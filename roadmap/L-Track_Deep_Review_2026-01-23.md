# L-Track Deep Review: Vollst√§ndige Typsicherheit

**Datum:** 2026-01-23
**Scope:** Datenfluss-Architektur & Agentic-Optimierung
**Status:** Analyse abgeschlossen

---

## Executive Summary

| Bereich | Score | Status |
|---------|-------|--------|
| Graph State-Typisierung | 6.5/10 | ‚ö†Ô∏è Schwach intern |
| Celery Task-Context | 4/10 | ‚ùå Kritisch |
| Domain Models | 8/10 | ‚úÖ Gut strukturiert |
| AX-Score (Agenten-Lesbarkeit) | 62% | ‚ö†Ô∏è L√ºckenhaft |

**Kernproblem:** Grenzen (API/Tool I/O) sind stark typisiert, interne State-√úbergaben nutzen `dict[str, Any]`.

---

## 1. Data Lineage Map: Wo Daten "im Dunkeln" flie√üen

### 1.1 Kritische Schattenzonen

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ TYPISIERT (Licht)          ‚îÇ UNTYPISIERT (Dunkel)              ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ API Input ‚Üí Pydantic        ‚îÇ Graph State["context"]: dict     ‚îÇ
‚îÇ Tool Input ‚Üí RetrieveInput  ‚îÇ Node Returns: dict[str, Any]     ‚îÇ
‚îÇ Tool Output ‚Üí RetrieveOutput‚îÇ Celery args[0]: Any              ‚îÇ
‚îÇ ScopeContext ‚Üí Pydantic     ‚îÇ meta.get("key_alias"): Any       ‚îÇ
‚îÇ BusinessContext ‚Üí Pydantic  ‚îÇ working_state["question"]: Any   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 1.2 Quantitative Analyse

| Kategorie | Typisiert | Untypisiert | Quote |
|-----------|-----------|-------------|-------|
| Graph State-Keys | 22 | 25 | 47% |
| Node-R√ºckgaben | 5 | 13 | 28% |
| Celery kwargs-Felder | 0 | 17 | 0% |
| Pydantic-Modelle Fields | 142 | 58 | 71% |

### 1.3 Hotspot-Dateien (Untypisierte dict-Zugriffe)

| Datei | dict-Ops | Risiko |
|-------|----------|--------|
| [common/celery.py](../common/celery.py#L267-559) | 18 | KRITISCH |
| [ai_core/graphs/technical/retrieval_augmented_generation.py](../ai_core/graphs/technical/retrieval_augmented_generation.py#L883-911) | 12 | KRITISCH |
| [ai_core/graphs/technical/universal_ingestion_graph.py](../ai_core/graphs/technical/universal_ingestion_graph.py#L199-474) | 8 | HOCH |
| [ai_core/graphs/technical/collection_search.py](../ai_core/graphs/technical/collection_search.py#L655-1094) | 6 | MITTEL |

---

## 2. Refactoring-Blaupause: Hierarchische Pydantic-Struktur

### 2.1 Ziel-Architektur

```
BaseContext (ABC)
‚îú‚îÄ‚îÄ ScopeContext ‚úÖ (implementiert)
‚îÇ   ‚îú‚îÄ‚îÄ tenant_id: str [PFLICHT]
‚îÇ   ‚îú‚îÄ‚îÄ trace_id: str [PFLICHT]
‚îÇ   ‚îú‚îÄ‚îÄ invocation_id: str [PFLICHT]
‚îÇ   ‚îî‚îÄ‚îÄ run_id | ingestion_run_id [mind. 1]
‚îÇ
‚îú‚îÄ‚îÄ BusinessContext ‚úÖ (implementiert)
‚îÇ   ‚îî‚îÄ‚îÄ case_id, collection_id, workflow_id, document_id [alle optional]
‚îÇ
‚îî‚îÄ‚îÄ TaskContext üÜï (zu erstellen)
    ‚îú‚îÄ‚îÄ scope: ScopeContext
    ‚îú‚îÄ‚îÄ business: BusinessContext
    ‚îî‚îÄ‚îÄ metadata: TaskContextMetadata
        ‚îú‚îÄ‚îÄ session_salt: str | None
        ‚îú‚îÄ‚îÄ priority: Literal["high", "low", "background"] | None
        ‚îî‚îÄ‚îÄ retry_count: int | None

BaseParams (ABC)
‚îú‚îÄ‚îÄ SearchParams üÜï
‚îÇ   ‚îú‚îÄ‚îÄ query: str
‚îÇ   ‚îú‚îÄ‚îÄ top_k: int
‚îÇ   ‚îî‚îÄ‚îÄ filters: FilterSpec | None
‚îÇ
‚îú‚îÄ‚îÄ HybridSearchParams üÜï (exists as dataclass ‚Üí Pydantic)
‚îÇ   ‚îî‚îÄ‚îÄ alpha, min_sim, vec_limit, lex_limit, trgm_limit, max_candidates
‚îÇ
‚îî‚îÄ‚îÄ FilterSpec üÜï
    ‚îú‚îÄ‚îÄ tenant_id: str [PFLICHT]
    ‚îú‚îÄ‚îÄ case_id: str | None
    ‚îî‚îÄ‚îÄ metadata: dict[str, Any] [Extension Point]

NodeReturns (ABC) üÜï
‚îú‚îÄ‚îÄ ValidateInputNodeOutput
‚îú‚îÄ‚îÄ DeduplicationNodeOutput
‚îú‚îÄ‚îÄ PersistNodeOutput
‚îî‚îÄ‚îÄ ProcessNodeOutput
```

### 2.2 Neue Pydantic-Modelle (zu erstellen)

#### TaskContext (f√ºr common/celery.py)

```python
class TaskScopeContext(BaseModel):
    """Infrastructure IDs aus ScopeContext."""
    tenant_id: str = Field(description="Mandant-UUID")
    trace_id: str = Field(description="Distributed Tracing ID")
    invocation_id: str = Field(description="Einzelner API-Aufruf")
    run_id: str | None = Field(None, description="LangGraph Execution ID")
    ingestion_run_id: str | None = Field(None, description="Document Ingestion ID")

    @model_validator(mode="after")
    def require_runtime_id(self):
        if not self.run_id and not self.ingestion_run_id:
            raise ValueError("At least one runtime ID required")
        return self

class TaskContextMetadata(BaseModel):
    """Runtime-Metadaten f√ºr Celery Tasks."""
    key_alias: str | None = None
    session_salt: str | None = None
    priority: Literal["high", "low", "background"] | None = None
    task_id: str | None = None
    queue: str | None = None
    retry_count: int | None = None

class TaskContext(BaseModel):
    """Vollst√§ndiger Task-Kontext f√ºr Celery."""
    scope: TaskScopeContext
    business: BusinessContext
    metadata: TaskContextMetadata = Field(default_factory=TaskContextMetadata)

    model_config = ConfigDict(frozen=True)
```

#### Graph Node Returns (f√ºr ai_core/graphs/)

```python
class ValidateInputNodeOutput(TypedDict):
    """Typisierte R√ºckgabe von validate_input_node."""
    error: str | None
    tool_context: ToolContext | None
    normalized_document: NormalizedDocument | None

class DeduplicationNodeOutput(TypedDict):
    """Typisierte R√ºckgabe von dedup_node."""
    dedup_status: Literal["new", "duplicate"]
    existing_document_ref: DocumentRef | None

class PersistNodeOutput(TypedDict):
    """Typisierte R√ºckgabe von persist_node."""
    ingestion_result: IngestionResult
    normalized_document: NormalizedDocument
```

---

## 3. Breaking-Change-Analyse

### 3.1 Tests die bei strict=True sofort fehlschlagen

| Test-Datei | Grund | Impact |
|------------|-------|--------|
| `test_tool_context.py` | Legacy args[0] meta passing | 5 Tests |
| `test_meta_normalization.py` | dict ohne scope_context | 8 Tests |
| `test_ingestion_orchestration.py` | Untypisierte kwargs | 3 Tests |
| `test_graph_tasks.py` | session_scope Tuple ohne Validierung | 2 Tests |
| `test_request_context_middleware.py` | key_alias raw dict access | 2 Tests |

**Gesamt: ~20 Tests m√ºssen migriert werden**

### 3.2 Breaking Points in common/celery.py

| Zeile | Code | Problem bei Strict |
|-------|------|-------------------|
| 285-287 | `args[0]` als meta | TypeError: Expected Mapping |
| 307 | `_from_meta(meta: Any)` | Muss Mapping sein |
| 361 | `meta.get("key_alias")` | Umgeht Pydantic |
| 478 | `pop("session_scope")` | Keine Tuple-Element-Pr√ºfung |
| 517 | `"||".join([None, ...])` | TypeError bei None |

### 3.3 Migrations-Phasen

| Phase | √Ñnderung | Tests betroffen |
|-------|----------|-----------------|
| **1** | Remove args[0]/args[1] fallback | ~5 |
| **2** | Enforce tool_context_from_meta() | ~15 |
| **3** | Validate session_scope tuple | ~3 |
| **4** | Remove key_alias raw dict | ~2 |
| **5** | Enforce BusinessContext separation | ~8 |

---

## 4. AX-Score: Agenten-Freundlichkeit

### 4.1 Scoring-Kriterien

- **0-25%**: Keine Beschreibungen, nur Typ-Hints
- **26-50%**: Teilweise Beschreibungen
- **51-75%**: Gute Beschreibungen, fehlende Literal Types
- **76-100%**: Vollst√§ndig dokumentiert, Literal Types, JSON Schema Export

### 4.2 Bewertung kritischer Modelle

| Modell | Felder | Mit Description | Literal | AX-Score |
|--------|--------|-----------------|---------|----------|
| ScopeContext | 10 | 10 | ‚úÖ | **100%** A+ |
| BusinessContext | 6 | 6 | ‚ùå | **95%** A |
| ToolContext | 9 | 6 | ‚úÖ | **85%** A |
| ChunkMeta | 21 | 0 | ‚ùå | **5%** F |
| RetrieveMeta | 13 | 0 | ‚ùå | **10%** D |
| ComposeOutput | 9 | 0 | ‚ùå | **10%** D |
| RetrieveInput | 7 | 0 | ‚ùå | **20%** D |

### 4.3 Kritische L√ºcken

**F-Grade (sofort beheben):**
- `ChunkMeta` (21 Felder ohne Beschreibung) ‚Üí Agents raten bei embedding_profile, chunker_mode
- `CrawlerIngestionPayload` (13 Felder) ‚Üí Kernvertrag f√ºr Ingestion

**D-Grade (kurzfristig):**
- `RetrieveMeta` ‚Üí alpha, min_sim, top_k_effective undokumentiert
- `ComposeOutput` ‚Üí reasoning, used_sources, suggested_followups unklar
- `RetrieveInput` ‚Üí query, filters, process, visibility ohne Kontext

### 4.4 Muster f√ºr Exzellenz (zu kopieren)

```python
# ScopeContext-Pattern (AX-Score 100%)
class ScopeContext(BaseModel):
    user_id: UserId = Field(
        default=None,
        description="User identity for User Request Hops. Must be absent for S2S."
    )

    @model_validator(mode="after")
    def validate_identity(self) -> "ScopeContext":
        """Ensure user_id and service_id are mutually exclusive."""
```

---

## 5. Empfehlungen & Roadmap

### 5.1 Sofortma√ünahmen (Woche 1)

1. **ChunkMeta dokumentieren** (21 Felder) - h√∂chstes AX-Impact
2. **RetrieveMeta dokumentieren** (13 Felder) - Hybrid Search verst√§ndlich machen
3. **TaskContext Pydantic erstellen** - common/celery.py typisieren

### 5.2 Kurzfristig (Woche 2-3)

4. **Node-Return TypedDicts** f√ºr Universal Ingestion Graph
5. **ComposeOutput dokumentieren** - LLM-Generierung transparent
6. **args[0] Fallback entfernen** in common/celery.py

### 5.3 Mittelfristig (Woche 4-6)

7. **HybridSearchParams ‚Üí Pydantic** (von dataclass)
8. **FilterSpec einf√ºhren** f√ºr typisierte Filter
9. **Graph State context: ToolContext** statt dict[str, Any]

### 5.4 Langfristig (Monat 2+)

10. **Pre-commit Hook** f√ºr undokumentierte Pydantic-Felder
11. **Pydantic Style Guide** in docs/
12. **100% AX-Score** f√ºr alle √∂ffentlichen Modelle

---

## 6. Aufwandssch√§tzung

| Track | Aufwand | Story Points | Scope |
|-------|---------|--------------|-------|
| **S-Track** | 2-3 PT | 5 SP | ChunkMeta + RetrieveMeta dokumentieren |
| **M-Track** | 8-10 PT | 21 SP | + TaskContext + Node Returns |
| **L-Track** | 20-25 PT | 55 SP | Vollst√§ndige Typsicherheit |

---

## 7. Dateien f√ºr Refactoring

### Priorit√§t KRITISCH

| Datei | √Ñnderung |
|-------|----------|
| [common/celery.py:267-559](../common/celery.py#L267-559) | TaskContext einf√ºhren |
| [ai_core/rag/ingestion_contracts.py:69](../ai_core/rag/ingestion_contracts.py#L69) | ChunkMeta dokumentieren |
| [ai_core/nodes/retrieve.py:100](../ai_core/nodes/retrieve.py#L100) | RetrieveMeta dokumentieren |

### Priorit√§t HOCH

| Datei | √Ñnderung |
|-------|----------|
| [ai_core/graphs/technical/universal_ingestion_graph.py](../ai_core/graphs/technical/universal_ingestion_graph.py) | Node-Return TypedDicts |
| [ai_core/graphs/technical/retrieval_augmented_generation.py:883](../ai_core/graphs/technical/retrieval_augmented_generation.py#L883) | working_state typisieren |
| [ai_core/nodes/compose.py](../ai_core/nodes/compose.py) | ComposeOutput dokumentieren |

### Priorit√§t MITTEL

| Datei | √Ñnderung |
|-------|----------|
| [ai_core/graphs/technical/collection_search.py:373](../ai_core/graphs/technical/collection_search.py#L373) | search State typisieren |
| [ai_core/rag/query_planner.py](../ai_core/rag/query_planner.py) | QueryPlan dokumentieren |

---

## 8. Metriken-Dashboard (Ziel-Werte)

| Metrik | Aktuell | Ziel M-Track | Ziel L-Track |
|--------|---------|--------------|--------------|
| Graph State-Typisierung | 47% | 75% | 95% |
| Node-Return Typisierung | 28% | 80% | 100% |
| Celery kwargs typisiert | 0% | 90% | 100% |
| AX-Score Durchschnitt | 62% | 80% | 95% |
| Tests ohne dict[str, Any] | ~20 | 0 | 0 |

