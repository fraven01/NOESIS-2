name: CI
on:
  pull_request:
    branches: [ "main" ]
  push:
    branches: [ "main" ]
jobs:
  verify-secrets:
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    name: Verify Secrets
    runs-on: ubuntu-latest
    steps:
      - name: Install jq
        shell: bash
        run: |
          sudo apt-get update -y >/dev/null 2>&1
          sudo apt-get install -y jq >/dev/null 2>&1
      - name: Verify GCP Credentials JSON structure
        shell: bash
        run: |
          echo "Verifying GCP_CREDENTIALS..."
          CREDS='${{ secrets.GCP_CREDENTIALS }}'
          if [ -z "$CREDS" ]; then
            echo "::error::GCP_CREDENTIALS is empty!"; exit 1;
          fi
          printf '%s' "$CREDS" > gcp_creds.json
          PARSED_PROJECT_ID=$(jq -r '.project_id' gcp_creds.json)
          echo "Project ID parsed from JSON: $PARSED_PROJECT_ID"
          if [ "$PARSED_PROJECT_ID" = "null" ] || [ -z "$PARSED_PROJECT_ID" ]; then
            echo "::error::Could not parse project_id from GCP_CREDENTIALS JSON."; exit 1;
          fi
      - name: Verify simple string secrets
        shell: bash
        run: |
          echo "Verifying GCP_PROJECT_ID..."
          PROJECT_ID="${{ secrets.GCP_PROJECT_ID }}"
          echo "Project ID Length: ${#PROJECT_ID}"
          echo "Project ID Starts with: ${PROJECT_ID:0:5}"
          echo "Project ID Ends with: ${PROJECT_ID: -5}"
          echo "Verifying GCP_REGION (non-sensitive)..."
          echo "Region: ${{ secrets.GCP_REGION }}"
          echo "Verifying GAR_REPOSITORY..."
          REPO="${{ secrets.GAR_REPOSITORY }}"
          echo "Repository Name Length: ${#REPO}"
          echo "Verifying CLOUD_SQL_CONNECTION_NAME..."
          CONN_NAME="${{ secrets.CLOUD_SQL_CONNECTION_NAME }}"
          echo "Connection Name Length: ${#CONN_NAME}"
      - name: Verify database secrets (length check only)
        shell: bash
        run: |
          echo "Verifying DB_USER/DB_PASSWORD/DB_NAME..."
          [ -n "${{ secrets.DB_USER }}" ] || { echo "::error::DB_USER is NOT set!"; exit 1; }
          [ -n "${{ secrets.DB_PASSWORD }}" ] || { echo "::error::DB_PASSWORD is NOT set!"; exit 1; }
          [ -n "${{ secrets.DB_NAME }}" ] || { echo "::error::DB_NAME is NOT set!"; exit 1; }
          echo "Verifying REDIS_URL..."
          [ -n "${{ secrets.REDIS_URL }}" ] || { echo "::error::REDIS_URL is NOT set!"; exit 1; }
          echo "Core infrastructure secrets verified."
      - name: Verify Django SECRET_KEY (presence only)
        shell: bash
        run: |
          echo "Verifying SECRET_KEY..."
          [ -n "${{ secrets.SECRET_KEY }}" ] || { echo "::error::SECRET_KEY is NOT set!"; exit 1; }
          echo "SECRET_KEY presence verified."
  lint:
    name: Lint
    runs-on: ubuntu-latest
    steps:
      - name: Debug GitHub context
        uses: actions/github-script@v7
        with:
          script: |
            core.info(`event: ${context.eventName}`)
            core.info(`actor: ${context.actor}`)
            core.info(`sender: ${context.payload?.sender?.login || 'n/a'}`)
            core.info(`pr.user: ${context.payload?.pull_request?.user?.login || 'n/a'}`)
            core.info(`head.ref: ${context.payload?.pull_request?.head?.ref || process.env.GITHUB_REF_NAME}`)
      - name: Checkout
        uses: actions/checkout@v4
      - name: Install ripgrep
        run: sudo apt-get update -y && sudo apt-get install -y ripgrep
      - name: Guard against legacy DB/Celery env lookups
        run: |
          if rg -n 'os\.getenv\("(?:DB_|CELERY_)' -g'*.py' .; then
            echo "::error::Found legacy os.getenv DB_/CELERY_ usage.";
            exit 1;
          fi
          if rg -n 'env\.(?:str|int|bool|list|float)?\("(?:DB_|CELERY_)' -g'*.py' .; then
            echo "::error::Found legacy env(\"DB_/CELERY_\") usage.";
            exit 1;
          fi
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"
          cache: "pip"
          cache-dependency-path: |
            requirements.txt
            requirements-dev.txt
      - name: Upgrade pip
        run: python -m pip install --upgrade pip
      - name: Install Python deps
        run: pip install -r requirements.txt -r requirements-dev.txt
      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: "lts/*"
          cache: "npm"
          cache-dependency-path: package-lock.json
      - name: Install Node deps
        run: npm ci
      - name: Run linters
        run: npm run lint
  test:
    name: Test (Python ${{ matrix.python-version }})
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ["3.12"]
    services:
      postgres:
        image: pgvector/pgvector:pg16
        env:
          POSTGRES_DB: noesis2_ci
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: postgres
        ports:
          - 5432:5432
        options: >-
          --health-cmd "pg_isready -U postgres" --health-interval 10s --health-timeout 5s --health-retries 5
      redis:
        image: redis:7-alpine
        ports:
          - 6379:6379
    env:
      SECRET_KEY: ci-secret
      DJANGO_SETTINGS_MODULE: noesis2.settings.development
      DATABASE_URL: postgresql://postgres:postgres@localhost:5432/noesis2_ci
      REDIS_URL: redis://localhost:6379/0
      AI_CORE_TEST_DATABASE_URL: postgresql://postgres:postgres@localhost:5432/postgres
      LANGFUSE_PUBLIC_KEY: ci-public
      LANGFUSE_SECRET_KEY: ci-secret
    steps:
      - name: Checkout
        uses: actions/checkout@v4
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}
          cache: "pip"
          cache-dependency-path: |
            requirements.txt
            requirements-dev.txt
      - name: Upgrade pip
        run: python -m pip install --upgrade pip
      - name: Install Python deps
        run: pip install -r requirements.txt -r requirements-dev.txt
      - name: Ensure pgvector extension is available
        run: |
          sudo apt-get update -y && sudo apt-get install -y postgresql-client
          psql "postgresql://postgres:postgres@localhost:5432/postgres" -c "CREATE EXTENSION IF NOT EXISTS vector;" || true
      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: "lts/*"
          cache: "npm"
          cache-dependency-path: package-lock.json
      - name: Install Node deps
        run: npm ci
      - name: Run public (shared) migrations
        run: python manage.py migrate_schemas --shared
      - name: Create CI tenant
        run: python manage.py create_tenant --schema=ci --name="CI" --domain=ci.localhost
      - name: Run tenant migrations
        run: python manage.py migrate_schemas --tenant
      - name: Run tests
        run: python -m pytest -q --cov=noesis2 --cov-report=xml
      - name: Upload coverage report
        uses: actions/upload-artifact@v4
        with:
          name: coverage-xml
          path: coverage.xml
  build:
    name: Build and Push Image
    runs-on: ubuntu-latest
    needs: test
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    env:
      REGISTRY_HOST: ${{ secrets.GCP_REGION }}-docker.pkg.dev
      IMAGE: ${{ secrets.GCP_REGION }}-docker.pkg.dev/${{ secrets.GCP_PROJECT_ID }}/${{ secrets.GAR_REPOSITORY }}/noesis2-web:${{ github.sha }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4
      - name: Google Cloud Auth
        uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCP_CREDENTIALS }}
      - name: Set up gcloud SDK
        uses: google-github-actions/setup-gcloud@v2
        with:
          project_id: ${{ secrets.GCP_PROJECT_ID }}
      - name: Configure Docker for Artifact Registry
        run: gcloud auth configure-docker "$REGISTRY_HOST" -q
        env:
          REGISTRY_HOST: ${{ env.REGISTRY_HOST }}
      - name: Build image
        run: docker build -t "$IMAGE" -f Dockerfile .
      - name: Push image
        run: docker push "$IMAGE"
      # Image tag is deterministic (${GITHUB_SHA}); downstream jobs can rebuild it.
  build-push-litellm:
    name: Publish LiteLLM proxy image
    runs-on: ubuntu-latest
    needs: test
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    outputs:
      image: ${{ steps.publish.outputs.image }}
    steps:
      - name: Google Cloud Auth
        uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCP_CREDENTIALS }}
      - name: Set up gcloud SDK
        uses: google-github-actions/setup-gcloud@v2
        with:
          project_id: ${{ secrets.GCP_PROJECT_ID }}
      - name: Configure Docker for Artifact Registry
        run: gcloud auth configure-docker ${{ secrets.GCP_REGION }}-docker.pkg.dev -q
      - name: Mirror upstream LiteLLM database image
        id: publish
        # Using litellm-database image keeps Prisma schema packaged to avoid ModuleNotFoundError: prisma.
        env:
          SOURCE_IMAGE: ghcr.io/berriai/litellm-database:main-stable
          TARGET_IMAGE: ${{ secrets.GCP_REGION }}-docker.pkg.dev/${{ secrets.GCP_PROJECT_ID }}/${{ secrets.GAR_REPOSITORY }}/litellm-proxy-db:${{ github.sha }}
        run: |
          docker pull "$SOURCE_IMAGE"
          docker tag "$SOURCE_IMAGE" "$TARGET_IMAGE"
          docker push "$TARGET_IMAGE"
          echo "image=$TARGET_IMAGE" >> "$GITHUB_OUTPUT"
  litellm-migrate:
    name: Run LiteLLM migrations
    runs-on: ubuntu-latest
    needs: build-push-litellm
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    steps:
      - name: Google Cloud Auth
        uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCP_CREDENTIALS }}
      - name: Set up gcloud SDK
        uses: google-github-actions/setup-gcloud@v2
        with:
          project_id: ${{ secrets.GCP_PROJECT_ID }}
      - &litellm_dburl
        name: Build LiteLLM DATABASE_URL
        shell: bash
        env:
          DB_USER: ${{ secrets.LITELLM_DB_USER || secrets.DB_USER }}
          DB_PASSWORD: ${{ secrets.LITELLM_DB_PASSWORD || secrets.DB_PASSWORD }}
          DB_NAME: ${{ secrets.LITELLM_DB_NAME || secrets.DB_NAME }}
          CLOUD_SQL_CONNECTION_NAME: ${{ secrets.CLOUD_SQL_CONNECTION_NAME }}
        run: |
          enc_pwd=$(python -c "from urllib.parse import quote; import os; print(quote(os.environ['DB_PASSWORD'], safe=''))")
          # Prisma rejects an empty host in the authority component. Use localhost and override via query param.
          # Cloud Run mounts the Cloud SQL Unix socket at /cloudsql/$CLOUD_SQL_CONNECTION_NAME
          LITELLM_DATABASE_URL="postgresql://${DB_USER}:${enc_pwd}@localhost/${DB_NAME}?host=/cloudsql/${CLOUD_SQL_CONNECTION_NAME}&port=5432"
          echo "LITELLM_DATABASE_URL=$LITELLM_DATABASE_URL" >> "$GITHUB_ENV"
      - name: Deploy LiteLLM migration job
        env:
          IMAGE: ${{ needs.build-push-litellm.outputs.image }}
          GCP_PROJECT_ID: ${{ secrets.GCP_PROJECT_ID }}
          GCP_REGION: ${{ secrets.GCP_REGION }}
          CLOUD_SQL_CONNECTION_NAME: ${{ secrets.CLOUD_SQL_CONNECTION_NAME }}
          GAR_REPOSITORY: ${{ secrets.GAR_REPOSITORY }}
        run: |
          # Fallback if upstream job output is unavailable
          if [ -z "${IMAGE:-}" ]; then
            IMAGE="${GCP_REGION}-docker.pkg.dev/${GCP_PROJECT_ID}/${GAR_REPOSITORY}/litellm-proxy-db:${GITHUB_SHA}"
          fi
          gcloud run jobs deploy litellm-migrate \
            --image "$IMAGE" \
            --project "$GCP_PROJECT_ID" \
            --region "$GCP_REGION" \
            --service-account "litellm-proxy@${GCP_PROJECT_ID}.iam.gserviceaccount.com" \
            --set-cloudsql-instances "$CLOUD_SQL_CONNECTION_NAME" \
            --set-env-vars DATABASE_URL="$LITELLM_DATABASE_URL",STORE_MODEL_IN_DB="True" \
            --command bash \
            --args=-lc \
            --args="npx prisma migrate deploy || prisma migrate deploy" \
            --task-timeout=600s \
            --max-retries=0
      - name: Execute LiteLLM migration job
        env:
          GCP_PROJECT_ID: ${{ secrets.GCP_PROJECT_ID }}
          GCP_REGION: ${{ secrets.GCP_REGION }}
        run: |
          gcloud run jobs execute litellm-migrate \
            --project "$GCP_PROJECT_ID" \
            --region "$GCP_REGION" \
            --wait
      - name: Dump LiteLLM migration logs
        if: always()
        env:
          GCP_PROJECT_ID: ${{ secrets.GCP_PROJECT_ID }}
          GCP_REGION: ${{ secrets.GCP_REGION }}
        run: |
          EXEC_ID=$(gcloud run jobs executions list --job litellm-migrate --project "$GCP_PROJECT_ID" --region "$GCP_REGION" --limit=1 --format='value(name)')
          if [ -n "$EXEC_ID" ]; then
            gcloud run jobs executions logs read "$EXEC_ID" --project "$GCP_PROJECT_ID" --region "$GCP_REGION" || true
          else
            echo "No LiteLLM migration execution found"
          fi
  deploy-litellm:
    name: Deploy LiteLLM proxy
    runs-on: ubuntu-latest
    needs: litellm-migrate
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    outputs:
      service_url: ${{ steps.deploy.outputs.service_url }}
    steps:
      - name: Google Cloud Auth
        uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCP_CREDENTIALS }}
      - name: Set up gcloud SDK
        uses: google-github-actions/setup-gcloud@v2
        with:
          project_id: ${{ secrets.GCP_PROJECT_ID }}
      - *litellm_dburl
      - name: Deploy LiteLLM service
        id: deploy
        env:
          IMAGE: ${{ needs.build-push-litellm.outputs.image }}
          GCP_PROJECT_ID: ${{ secrets.GCP_PROJECT_ID }}
          GCP_REGION: ${{ secrets.GCP_REGION }}
          CLOUD_SQL_CONNECTION_NAME: ${{ secrets.CLOUD_SQL_CONNECTION_NAME }}
          LITELLM_MASTER_KEY: ${{ secrets.LITELLM_MASTER_KEY }}
          VERTEXAI_LOCATION: ${{ secrets.VERTEXAI_LOCATION }}
          PORT: 8080
          GAR_REPOSITORY: ${{ secrets.GAR_REPOSITORY }}
        # Cloud SQL unix-domain socket is more stable than TCP in Cloud Run and avoids IP allowlisting.
        # Forcing the litellm CLI ensures it binds to $PORT, preventing startup probe failures.
        run: |
          # Fallback if upstream job output is unavailable
          if [ -z "${IMAGE:-}" ]; then
            IMAGE="${GCP_REGION}-docker.pkg.dev/${GCP_PROJECT_ID}/${GAR_REPOSITORY}/litellm-proxy-db:${GITHUB_SHA}"
          fi
          gcloud run deploy litellm-proxy \
            --image "$IMAGE" \
            --project "$GCP_PROJECT_ID" \
            --region "$GCP_REGION" \
            --service-account "litellm-proxy@${GCP_PROJECT_ID}.iam.gserviceaccount.com" \
            --allow-unauthenticated \
            --add-cloudsql-instances "$CLOUD_SQL_CONNECTION_NAME" \
            --cpu=1 \
            --memory=1Gi \
            --concurrency=80 \
            --command litellm \
            --args="--host=0.0.0.0" \
            --args="--port=${PORT:-8080}" \
            --args="--num_workers=1" \
            --set-env-vars DATABASE_URL="$LITELLM_DATABASE_URL",LITELLM_MASTER_KEY="$LITELLM_MASTER_KEY",VERTEXAI_PROJECT="$GCP_PROJECT_ID",VERTEXAI_LOCATION="$VERTEXAI_LOCATION",STORE_MODEL_IN_DB="True"
          echo "Cloud Run service account carries Vertex AI User role (configured out-of-band)."
          SERVICE_URL=$(gcloud run services describe litellm-proxy --project "$GCP_PROJECT_ID" --region "$GCP_REGION" --format='value(status.url)')
          echo "service_url=$SERVICE_URL" >> "$GITHUB_OUTPUT"
          echo "LiteLLM service URL: $SERVICE_URL"
  smoke-litellm:
    name: Smoke test LiteLLM proxy
    runs-on: ubuntu-latest
    needs: deploy-litellm
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    env:
      SERVICE_URL: ${{ needs.deploy-litellm.outputs.service_url }}
      LITELLM_MASTER_KEY: ${{ secrets.LITELLM_MASTER_KEY }}
      GCP_PROJECT_ID: ${{ secrets.GCP_PROJECT_ID }}
      GCP_REGION: ${{ secrets.GCP_REGION }}
    steps:
      - name: Google Cloud Auth
        uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCP_CREDENTIALS }}
      - name: Set up gcloud SDK
        uses: google-github-actions/setup-gcloud@v2
        with:
          project_id: ${{ secrets.GCP_PROJECT_ID }}
      - name: Resolve SERVICE_URL if empty
        shell: bash
        run: |
          if [ -z "${SERVICE_URL:-}" ]; then
            URL=$(gcloud run services describe litellm-proxy --project "$GCP_PROJECT_ID" --region "$GCP_REGION" --format='value(status.url)')
            echo "Resolved SERVICE_URL=$URL"
            echo "SERVICE_URL=$URL" >> "$GITHUB_ENV"
          fi
      - name: Verify LiteLLM /health
        run: |
          BODY=$(mktemp)
          STATUS=$(curl -sS -o "$BODY" -w "%{http_code}" "$SERVICE_URL/health/liveliness")
          echo "health_status=$STATUS"
          head -c 200 "$BODY" || true
      - name: Create LiteLLM virtual key
        env:
          SERVICE_URL: ${{ env.SERVICE_URL }}
          LITELLM_MASTER_KEY: ${{ env.LITELLM_MASTER_KEY }}
        run: |
          BODY=$(mktemp)
          DATA='{"key_alias":"ci-smoke-key","max_budget":1.0,"budget_duration":"monthly","block_after_limit":true}'
          STATUS=$(curl -sS -o "$BODY" -w "%{http_code}" \
            -X POST "$SERVICE_URL/key/create" \
            -H "Authorization: Bearer $LITELLM_MASTER_KEY" \
            -H "Content-Type: application/json" \
            --data-raw "$DATA")
          echo "key_create_status=$STATUS"
          head -c 200 "$BODY" || true
          VIRTUAL_KEY=$(python -c "import json,sys; d=json.load(open(sys.argv[1])); print(d.get('key') or d.get('api_key') or '')" "$BODY")
          if [ -n "$VIRTUAL_KEY" ]; then
            echo "LITELLM_VIRTUAL_KEY=$VIRTUAL_KEY" >> "$GITHUB_ENV"
          else
            echo "Falling back to master key for smoke call"
            echo "LITELLM_VIRTUAL_KEY=$LITELLM_MASTER_KEY" >> "$GITHUB_ENV"
          fi
      - name: List available models
        env:
          SERVICE_URL: ${{ env.SERVICE_URL }}
        run: |
          AUTH_KEY="${LITELLM_VIRTUAL_KEY:-$LITELLM_MASTER_KEY}"
          BODY=$(mktemp)
          STATUS=$(curl -sS -o "$BODY" -w "%{http_code}" \
            -H "Authorization: Bearer $AUTH_KEY" \
            "$SERVICE_URL/v1/models")
          echo "models_status=$STATUS"
          python -c 'import json, sys; code = "try:\\n    data=json.load(open(sys.argv[1]))\\n    arr=data.get(\\"data\\") if isinstance(data, dict) else data\\n    if isinstance(arr, list):\\n        for m in arr[:10]:\\n            mid=(m.get(\\"id\\") if isinstance(m, dict) else str(m))\\n            print(mid)\\n    else:\\n        print(json.dumps(data)[:500])\\nexcept Exception as e:\\n    print(\\"models_parse_error:\\", e)"; exec(code)' "$BODY" || true
      - name: Chat completion smoke test
        env:
          SERVICE_URL: ${{ env.SERVICE_URL }}
        run: |
          AUTH_KEY="${LITELLM_VIRTUAL_KEY:-$LITELLM_MASTER_KEY}"
          BODY=$(mktemp)
          CHAT='{"model":"vertex_ai/gemini-1.5-flash-001","messages":[{"role":"user","content":"ping"}],"max_tokens":8}'
          STATUS=$(curl -sS -o "$BODY" -w "%{http_code}" \
            -X POST "$SERVICE_URL/v1/chat/completions" \
            -H "Authorization: Bearer $AUTH_KEY" \
            -H "Content-Type: application/json" \
            --data-raw "$CHAT")
          echo "chat_completion_status=$STATUS"
          head -c 200 "$BODY" || true
  migrate:
    name: Run DB Migrations
    runs-on: ubuntu-latest
    needs: build
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    steps:
      - name: Build DATABASE_URL
        shell: bash
        env:
          DB_USER: ${{ secrets.DB_USER }}
          DB_PASSWORD: ${{ secrets.DB_PASSWORD }}
          DB_NAME: ${{ secrets.DB_NAME }}
        run: |
          enc_pwd=$(python -c "from urllib.parse import quote; import os; print(quote(os.environ['DB_PASSWORD'], safe=''))")
          echo "DATABASE_URL=postgresql://${DB_USER}:${enc_pwd}@/${DB_NAME}" >> "$GITHUB_ENV"
      - name: Google Cloud Auth
        uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCP_CREDENTIALS }}
      - name: Set up gcloud SDK
        uses: google-github-actions/setup-gcloud@v2
        with:
          project_id: ${{ secrets.GCP_PROJECT_ID }}
      - name: Run migrations via Cloud Run Job
        env:
          IMAGE: ${{ secrets.GCP_REGION }}-docker.pkg.dev/${{ secrets.GCP_PROJECT_ID }}/${{ secrets.GAR_REPOSITORY }}/noesis2-web:${{ github.sha }}
          GCP_PROJECT_ID: ${{ secrets.GCP_PROJECT_ID }}
          GCP_REGION: ${{ secrets.GCP_REGION }}
          CLOUD_SQL_CONNECTION_NAME: ${{ secrets.CLOUD_SQL_CONNECTION_NAME }}
          SECRET_KEY: ${{ secrets.SECRET_KEY }}
          REDIS_URL: ${{ secrets.REDIS_URL }}
        run: |
          gcloud run jobs deploy noesis2-migrate \
            --image "$IMAGE" \
            --project "$GCP_PROJECT_ID" \
            --region "$GCP_REGION" \
            --max-retries=0 \
            --task-timeout=600s \
            --set-cloudsql-instances "$CLOUD_SQL_CONNECTION_NAME" \
            --set-env-vars DJANGO_SETTINGS_MODULE=noesis2.settings.production,GOOGLE_CLOUD_PROJECT="$GCP_PROJECT_ID",CLOUD_SQL_CONNECTION_NAME="$CLOUD_SQL_CONNECTION_NAME",SECRET_KEY="$SECRET_KEY",DATABASE_URL="$DATABASE_URL",REDIS_URL="$REDIS_URL" \
            --command python \
            --args manage.py,migrate_schemas,--noinput
  rag-migrate-staging:
    name: RAG Schema Migration (staging)
    runs-on: ubuntu-latest
    needs: migrate
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    steps:
      - name: Build DATABASE_URL
        shell: bash
        env:
          DB_USER: ${{ secrets.DB_USER }}
          DB_PASSWORD: ${{ secrets.DB_PASSWORD }}
          DB_NAME: ${{ secrets.DB_NAME }}
        run: |
          enc_pwd=$(python -c "from urllib.parse import quote; import os; print(quote(os.environ['DB_PASSWORD'], safe=''))")
          echo "DATABASE_URL=postgresql://${DB_USER}:${enc_pwd}@/${DB_NAME}" >> "$GITHUB_ENV"
      - name: Google Cloud Auth
        uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCP_CREDENTIALS }}
      - name: Set up gcloud SDK
        uses: google-github-actions/setup-gcloud@v2
        with:
          project_id: ${{ secrets.GCP_PROJECT_ID }}
      - name: Deploy RAG migrate job
        env:
          IMAGE: ${{ secrets.GCP_REGION }}-docker.pkg.dev/${{ secrets.GCP_PROJECT_ID }}/${{ secrets.GAR_REPOSITORY }}/noesis2-web:${{ github.sha }}
          GCP_PROJECT_ID: ${{ secrets.GCP_PROJECT_ID }}
          GCP_REGION: ${{ secrets.GCP_REGION }}
          CLOUD_SQL_CONNECTION_NAME: ${{ secrets.CLOUD_SQL_CONNECTION_NAME }}
          SECRET_KEY: ${{ secrets.SECRET_KEY }}
          REDIS_URL: ${{ secrets.REDIS_URL }}
        run: |
          gcloud run jobs deploy noesis2-rag-migrate \
            --image "$IMAGE" \
            --project "$GCP_PROJECT_ID" \
            --region "$GCP_REGION" \
            --max-retries=0 \
            --task-timeout=600s \
            --set-cloudsql-instances "$CLOUD_SQL_CONNECTION_NAME" \
            --set-env-vars DJANGO_SETTINGS_MODULE=noesis2.settings.production,GOOGLE_CLOUD_PROJECT="$GCP_PROJECT_ID",CLOUD_SQL_CONNECTION_NAME="$CLOUD_SQL_CONNECTION_NAME",SECRET_KEY="$SECRET_KEY",DATABASE_URL="$DATABASE_URL",REDIS_URL="$REDIS_URL" \
            --command python \
            --args manage.py,apply_rag_schema
      - name: Execute RAG migrate job
        env:
          GCP_PROJECT_ID: ${{ secrets.GCP_PROJECT_ID }}
          GCP_REGION: ${{ secrets.GCP_REGION }}
        run: |
          gcloud run jobs execute noesis2-rag-migrate \
            --project "$GCP_PROJECT_ID" \
            --region "$GCP_REGION" \
            --wait
  seed-staging:
    name: Seed Staging Data
    runs-on: ubuntu-latest
    needs: migrate
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    steps:
      - name: Build DATABASE_URL
        shell: bash
        env:
          DB_USER: ${{ secrets.DB_USER }}
          DB_PASSWORD: ${{ secrets.DB_PASSWORD }}
          DB_NAME: ${{ secrets.DB_NAME }}
        run: |
          enc_pwd=$(python -c "from urllib.parse import quote; import os; print(quote(os.environ['DB_PASSWORD'], safe=''))")
          echo "DATABASE_URL=postgresql://${DB_USER}:${enc_pwd}@/${DB_NAME}" >> "$GITHUB_ENV"
      - name: Checkout
        uses: actions/checkout@v4
      - name: Google Cloud Auth
        uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCP_CREDENTIALS }}
      - name: Set up gcloud SDK
        uses: google-github-actions/setup-gcloud@v2
        with:
          project_id: ${{ secrets.GCP_PROJECT_ID }}
      - name: Seed demo tenant and bind Cloud Run host
        env:
          IMAGE: ${{ secrets.GCP_REGION }}-docker.pkg.dev/${{ secrets.GCP_PROJECT_ID }}/${{ secrets.GAR_REPOSITORY }}/noesis2-web:${{ github.sha }}
          GCP_PROJECT_ID: ${{ secrets.GCP_PROJECT_ID }}
          GCP_REGION: ${{ secrets.GCP_REGION }}
          CLOUD_SQL_CONNECTION_NAME: ${{ secrets.CLOUD_SQL_CONNECTION_NAME }}
          SECRET_KEY: ${{ secrets.SECRET_KEY }}
          REDIS_URL: ${{ secrets.REDIS_URL }}
          STAGING_HOST: ${{ secrets.STAGING_HOST }}
        run: |
          gcloud run jobs deploy noesis2-seed \
            --image "$IMAGE" \
            --project "$GCP_PROJECT_ID" \
            --region "$GCP_REGION" \
            --max-retries=0 \
            --task-timeout=600s \
            --set-cloudsql-instances "$CLOUD_SQL_CONNECTION_NAME" \
            --set-env-vars DJANGO_SETTINGS_MODULE=noesis2.settings.production,GOOGLE_CLOUD_PROJECT="$GCP_PROJECT_ID",CLOUD_SQL_CONNECTION_NAME="$CLOUD_SQL_CONNECTION_NAME",SECRET_KEY="$SECRET_KEY",DATABASE_URL="$DATABASE_URL",REDIS_URL="$REDIS_URL" \
            --command bash \
            --args -lc,"python manage.py bootstrap_public_tenant --domain localhost && python manage.py create_demo_data --domain=\"$STAGING_HOST\""
      - name: Execute seed job
        env:
          GCP_PROJECT_ID: ${{ secrets.GCP_PROJECT_ID }}
          GCP_REGION: ${{ secrets.GCP_REGION }}
        run: |
          gcloud run jobs execute noesis2-seed \
            --project "$GCP_PROJECT_ID" \
            --region "$GCP_REGION" \
            --wait
          gcloud run jobs execute noesis2-migrate --project "$GCP_PROJECT_ID" --region "$GCP_REGION" --wait
  deploy-staging:
    name: Deploy to Cloud Run (staging)
    runs-on: ubuntu-latest
    needs: rag-migrate-staging
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    env:
      IMAGE: ${{ secrets.GCP_REGION }}-docker.pkg.dev/${{ secrets.GCP_PROJECT_ID }}/${{ secrets.GAR_REPOSITORY }}/noesis2-web:${{ github.sha }}
    steps:
      - name: Build DATABASE_URL
        shell: bash
        env:
          DB_USER: ${{ secrets.DB_USER }}
          DB_PASSWORD: ${{ secrets.DB_PASSWORD }}
          DB_NAME: ${{ secrets.DB_NAME }}
        run: |
          enc_pwd=$(python -c "from urllib.parse import quote; import os; print(quote(os.environ['DB_PASSWORD'], safe=''))")
          echo "DATABASE_URL=postgresql://${DB_USER}:${enc_pwd}@/${DB_NAME}" >> "$GITHUB_ENV"
      - name: Google Cloud Auth
        uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCP_CREDENTIALS }}
      - name: Set up gcloud SDK
        uses: google-github-actions/setup-gcloud@v2
        with:
          project_id: ${{ secrets.GCP_PROJECT_ID }}
      - name: Deploy to Cloud Run (staging)
        uses: google-github-actions/deploy-cloudrun@v2.1.0
        with:
          service: noesis-2-staging
          image: ${{ env.IMAGE }}
          project_id: ${{ secrets.GCP_PROJECT_ID }}
          region: ${{ secrets.GCP_REGION }}
          flags: '--add-cloudsql-instances=${{ secrets.CLOUD_SQL_CONNECTION_NAME }} --allow-unauthenticated'
          env_vars: |
            DJANGO_SETTINGS_MODULE=noesis2.settings.production
            GOOGLE_CLOUD_PROJECT=${{ secrets.GCP_PROJECT_ID }}
            CLOUD_SQL_CONNECTION_NAME=${{ secrets.CLOUD_SQL_CONNECTION_NAME }}
            SECRET_KEY=${{ secrets.SECRET_KEY }}
            DATABASE_URL=${{ env.DATABASE_URL }}
            REDIS_URL=${{ secrets.REDIS_URL }}
  smoke-staging:
    name: Smoke Test (staging)
    runs-on: ubuntu-latest
    needs: deploy-staging
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    steps:
      - name: Google Cloud Auth
        uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCP_CREDENTIALS }}
      - name: Set up gcloud SDK
        uses: google-github-actions/setup-gcloud@v2
        with:
          project_id: ${{ secrets.GCP_PROJECT_ID }}
      - name: Resolve service URL
        id: svc
        env:
          GCP_PROJECT_ID: ${{ secrets.GCP_PROJECT_ID }}
          GCP_REGION: ${{ secrets.GCP_REGION }}
        run: |
          URL=$(gcloud run services describe noesis-2-staging \
            --project "$GCP_PROJECT_ID" --region "$GCP_REGION" \
            --format='value(status.url)')
          echo "url=$URL" >> "$GITHUB_OUTPUT"
      - name: Ping /ai/ping/
        env:
          URL: ${{ steps.svc.outputs.url }}
        run: |
          echo "Pinging: ${URL}/ai/ping/"
          curl -fsSI -H 'X-Tenant-Schema: demo' -H 'X-Tenant-ID: demo-tenant' -H 'X-Case-ID: smoke' "$URL/ai/ping/" | head -n 1
      - name: POST /ai/scope
        env:
          URL: ${{ steps.svc.outputs.url }}
        run: |
          curl -fsS -X POST \
            -H 'Content-Type: application/json' \
            -H 'X-Tenant-Schema: demo' -H 'X-Tenant-ID: demo-tenant' -H 'X-Case-ID: smoke' \
            --data '{"hello":"world"}' \
            "$URL/ai/scope/" | head -c 200; echo
  deploy-worker-staging:
    name: Deploy Worker (staging) [disabled; moving to GKE]
    runs-on: ubuntu-latest
    needs: rag-migrate-staging
    if: false
    env:
      IMAGE: ${{ secrets.GCP_REGION }}-docker.pkg.dev/${{ secrets.GCP_PROJECT_ID }}/${{ secrets.GAR_REPOSITORY }}/noesis2-web:${{ github.sha }}
    steps:
      - name: Build DATABASE_URL
        shell: bash
        env:
          DB_USER: ${{ secrets.DB_USER }}
          DB_PASSWORD: ${{ secrets.DB_PASSWORD }}
          DB_NAME: ${{ secrets.DB_NAME }}
        run: |
          enc_pwd=$(python -c "from urllib.parse import quote; import os; print(quote(os.environ['DB_PASSWORD'], safe=''))")
          echo "DATABASE_URL=postgresql://${DB_USER}:${enc_pwd}@/${DB_NAME}" >> "$GITHUB_ENV"
      - name: Google Cloud Auth
        uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCP_CREDENTIALS }}
      - name: Set up gcloud SDK
        uses: google-github-actions/setup-gcloud@v2
        with:
          project_id: ${{ secrets.GCP_PROJECT_ID }}
      - name: Deploy Worker service (staging)
        uses: google-github-actions/deploy-cloudrun@v2.1.0
        with:
          service: noesis-2-worker-staging
          image: ${{ env.IMAGE }}
          project_id: ${{ secrets.GCP_PROJECT_ID }}
          region: ${{ secrets.GCP_REGION }}
          flags: >-
            --add-cloudsql-instances=${{ secrets.CLOUD_SQL_CONNECTION_NAME }}
            --allow-unauthenticated
            --command=bash
            --args="-lc,python -m noesis2.healthsrv & celery -A noesis2 worker -l info"
          env_vars: |
            DJANGO_SETTINGS_MODULE=noesis2.settings.production
            GOOGLE_CLOUD_PROJECT=${{ secrets.GCP_PROJECT_ID }}
            CLOUD_SQL_CONNECTION_NAME=${{ secrets.CLOUD_SQL_CONNECTION_NAME }}
            SECRET_KEY=${{ secrets.SECRET_KEY }}
            DATABASE_URL=${{ env.DATABASE_URL }}
            REDIS_URL=${{ secrets.REDIS_URL }}
          # Note: Cloud SQL attachment is handled via flags; no metadata YAML.
  deploy-beat-staging:
    name: Deploy Beat (staging) [disabled; moving to GKE]
    runs-on: ubuntu-latest
    needs: rag-migrate-staging
    if: false
    env:
      IMAGE: ${{ secrets.GCP_REGION }}-docker.pkg.dev/${{ secrets.GCP_PROJECT_ID }}/${{ secrets.GAR_REPOSITORY }}/noesis2-web:${{ github.sha }}
    steps:
      - name: Google Cloud Auth
        uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCP_CREDENTIALS }}
      - name: Set up gcloud SDK
        uses: google-github-actions/setup-gcloud@v2
        with:
          project_id: ${{ secrets.GCP_PROJECT_ID }}
      - name: Deploy Beat service (staging)
        uses: google-github-actions/deploy-cloudrun@v2.1.0
        with:
          service: noesis-2-beat-staging
          image: ${{ env.IMAGE }}
          project_id: ${{ secrets.GCP_PROJECT_ID }}
          region: ${{ secrets.GCP_REGION }}
          flags: >-
            --add-cloudsql-instances=${{ secrets.CLOUD_SQL_CONNECTION_NAME }}
            --allow-unauthenticated
            --command=bash
            --args="-lc,python -m noesis2.healthsrv & celery -A noesis2 beat -l info"
          env_vars: |
            DJANGO_SETTINGS_MODULE=noesis2.settings.production
            GOOGLE_CLOUD_PROJECT=${{ secrets.GCP_PROJECT_ID }}
            CLOUD_SQL_CONNECTION_NAME=${{ secrets.CLOUD_SQL_CONNECTION_NAME }}
            SECRET_KEY=${{ secrets.SECRET_KEY }}
            DATABASE_URL=${{ env.DATABASE_URL }}
            REDIS_URL=${{ secrets.REDIS_URL }}
          # Note: Cloud SQL attachment is handled via flags; no metadata YAML.
  deploy-gke-workers:
    name: Deploy Workers to GKE
    runs-on: ubuntu-latest
    needs: build
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    steps:
      - name: Checkout
        uses: actions/checkout@v4
      - name: Google Cloud Auth
        uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCP_CREDENTIALS }}
      - name: Set up gcloud SDK
        uses: google-github-actions/setup-gcloud@v2
        with:
          project_id: ${{ secrets.GCP_PROJECT_ID }}
      - name: Get GKE credentials
        uses: google-github-actions/get-gke-credentials@v2
        with:
          cluster_name: ${{ secrets.GKE_CLUSTER_NAME }}
          location: ${{ secrets.GKE_LOCATION }}
      - name: Create namespace & SA (idempotent)
        run: |
          kubectl apply -f k8s/namespace.yaml
          kubectl apply -f k8s/serviceaccount.yaml
      - name: Create/Update app-secrets from GitHub Secrets
        env:
          SECRET_KEY: ${{ secrets.SECRET_KEY }}
          DB_USER: ${{ secrets.DB_USER }}
          DB_PASSWORD: ${{ secrets.DB_PASSWORD }}
          DB_NAME: ${{ secrets.DB_NAME }}
          REDIS_URL: ${{ secrets.REDIS_URL }}
        run: |
          enc_pwd=$(python -c "from urllib.parse import quote; import os; print(quote(os.environ['DB_PASSWORD'], safe=''))")
          kubectl create secret generic app-secrets \
            -n noesis2 \
            --from-literal=SECRET_KEY="$SECRET_KEY" \
            --from-literal=DB_USER="$DB_USER" \
            --from-literal=DB_PASSWORD="$DB_PASSWORD" \
            --from-literal=DATABASE_URL="postgresql://${DB_USER}:${enc_pwd}@127.0.0.1:5432/${DB_NAME}" \
            --from-literal=REDIS_URL="$REDIS_URL" \
            --dry-run=client -o yaml | kubectl apply -f -
      - name: Apply worker/beat manifests
        env:
          IMAGE: ${{ secrets.GCP_REGION }}-docker.pkg.dev/${{ secrets.GCP_PROJECT_ID }}/${{ secrets.GAR_REPOSITORY }}/noesis2-web:${{ github.sha }}
          PROJECT: ${{ secrets.GCP_PROJECT_ID }}
          REGION: ${{ secrets.GCP_REGION }}
          INSTANCE: ${{ secrets.CLOUD_SQL_CONNECTION_NAME }}
        run: |
          sed -e "s#REGION-docker.pkg.dev/PROJECT/REPO/noesis2-web:SHA#${IMAGE}#g" \
              -e "s#PROJECT:REGION:INSTANCE#${INSTANCE}#g" \
              k8s/worker-deployment.yaml | kubectl apply -f -
          sed -e "s#REGION-docker.pkg.dev/PROJECT/REPO/noesis2-web:SHA#${IMAGE}#g" \
              -e "s#PROJECT:REGION:INSTANCE#${INSTANCE}#g" \
              k8s/beat-deployment.yaml | kubectl apply -f -
          kubectl apply -f k8s/worker-hpa.yaml
      - name: Wait for rollouts (with diagnostics)
        run: |
          set +e
          kubectl rollout status deploy/celery-worker -n noesis2 --timeout=300s
          STATUS=$?
          if [ $STATUS -ne 0 ]; then
            echo "Worker rollout failed; collecting diagnostics"
            kubectl get pods -n noesis2 -o wide
            kubectl describe deploy/celery-worker -n noesis2 || true
            kubectl describe pods -n noesis2 -l app=celery-worker || true
            kubectl logs -n noesis2 deploy/celery-worker --all-containers --tail=200 || true
            exit $STATUS
          fi
          kubectl rollout status deploy/celery-beat -n noesis2 --timeout=300s
          STATUS=$?
          if [ $STATUS -ne 0 ]; then
            echo "Beat rollout failed; collecting diagnostics"
            kubectl get pods -n noesis2 -o wide
            kubectl describe deploy/celery-beat -n noesis2 || true
            kubectl describe pods -n noesis2 -l app=celery-beat || true
            kubectl logs -n noesis2 deploy/celery-beat --all-containers --tail=200 || true
            exit $STATUS
          fi
