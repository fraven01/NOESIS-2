name: CI

on:
  pull_request:
    branches: [ "main" ]
  push:
    branches: [ "main" ]

jobs:
  verify-secrets:
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    name: Verify Secrets
    runs-on: ubuntu-latest
    steps:
      - name: Install jq
        shell: bash
        run: |
          sudo apt-get update -y >/dev/null 2>&1
          sudo apt-get install -y jq >/dev/null 2>&1

      - name: Verify GCP Credentials JSON structure
        shell: bash
        run: |
          echo "Verifying GCP_CREDENTIALS..."
          CREDS='${{ secrets.GCP_CREDENTIALS }}'
          if [ -z "$CREDS" ]; then
            echo "::error::GCP_CREDENTIALS is empty!"; exit 1;
          fi
          printf '%s' "$CREDS" > gcp_creds.json
          PARSED_PROJECT_ID=$(jq -r '.project_id' gcp_creds.json)
          echo "Project ID parsed from JSON: $PARSED_PROJECT_ID"
          if [ "$PARSED_PROJECT_ID" = "null" ] || [ -z "$PARSED_PROJECT_ID" ]; then
            echo "::error::Could not parse project_id from GCP_CREDENTIALS JSON."; exit 1;
          fi

      - name: Verify simple string secrets
        shell: bash
        run: |
          echo "Verifying GCP_PROJECT_ID..."
          PROJECT_ID="${{ secrets.GCP_PROJECT_ID }}"
          echo "Project ID Length: ${#PROJECT_ID}"
          echo "Project ID Starts with: ${PROJECT_ID:0:5}"
          echo "Project ID Ends with: ${PROJECT_ID: -5}"

          echo "Verifying GCP_REGION (non-sensitive)..."
          echo "Region: ${{ secrets.GCP_REGION }}"

          echo "Verifying GAR_REPOSITORY..."
          REPO="${{ secrets.GAR_REPOSITORY }}"
          echo "Repository Name Length: ${#REPO}"

          echo "Verifying CLOUD_SQL_CONNECTION_NAME..."
          CONN_NAME="${{ secrets.CLOUD_SQL_CONNECTION_NAME }}"
          echo "Connection Name Length: ${#CONN_NAME}"

      - name: Verify database secrets (length check only)
        shell: bash
        run: |
          echo "Verifying DB_USER/DB_PASSWORD/DB_NAME..."
          [ -n "${{ secrets.DB_USER }}" ] || { echo "::error::DB_USER is NOT set!"; exit 1; }
          [ -n "${{ secrets.DB_PASSWORD }}" ] || { echo "::error::DB_PASSWORD is NOT set!"; exit 1; }
          [ -n "${{ secrets.DB_NAME }}" ] || { echo "::error::DB_NAME is NOT set!"; exit 1; }
          echo "Verifying REDIS_URL..."
          [ -n "${{ secrets.REDIS_URL }}" ] || { echo "::error::REDIS_URL is NOT set!"; exit 1; }
          echo "Core infrastructure secrets verified."

      - name: Verify Django SECRET_KEY (presence only)
        shell: bash
        run: |
          echo "Verifying SECRET_KEY..."
          [ -n "${{ secrets.SECRET_KEY }}" ] || { echo "::error::SECRET_KEY is NOT set!"; exit 1; }
          echo "SECRET_KEY presence verified."

  lint:
    name: Lint
    runs-on: ubuntu-latest
    steps:
      - name: Debug GitHub context
        uses: actions/github-script@v7
        with:
          script: |
            core.info(`event: ${context.eventName}`)
            core.info(`actor: ${context.actor}`)
            core.info(`sender: ${context.payload?.sender?.login || 'n/a'}`)
            core.info(`pr.user: ${context.payload?.pull_request?.user?.login || 'n/a'}`)
            core.info(`head.ref: ${context.payload?.pull_request?.head?.ref || process.env.GITHUB_REF_NAME}`)
      - name: Checkout
        uses: actions/checkout@v4

      - name: Install ripgrep
        run: sudo apt-get update -y && sudo apt-get install -y ripgrep

      - name: Guard against legacy DB/Celery env lookups
        run: |
          if rg -n 'os\.getenv\("(?:DB_|CELERY_)' -g'*.py' .; then
            echo "::error::Found legacy os.getenv DB_/CELERY_ usage.";
            exit 1;
          fi
          if rg -n 'env\.(?:str|int|bool|list|float)?\("(?:DB_|CELERY_)' -g'*.py' .; then
            echo "::error::Found legacy env(\"DB_/CELERY_\") usage.";
            exit 1;
          fi

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"
          cache: "pip"
          cache-dependency-path: |
            requirements.txt
            requirements-dev.txt

      - name: Upgrade pip
        run: python -m pip install --upgrade pip

      - name: Install Python deps
        run: pip install -r requirements.txt -r requirements-dev.txt

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: "lts/*"
          cache: "npm"
          cache-dependency-path: package-lock.json

      - name: Install Node deps
        run: npm ci

      - name: Run linters
        run: npm run lint

  test:
    name: Test (Python ${{ matrix.python-version }})
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ["3.12"]
    services:
      postgres:
        image: pgvector/pgvector:pg16
        env:
          POSTGRES_DB: noesis2_ci
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: postgres
        ports:
          - 5432:5432
        options: >-
          --health-cmd "pg_isready -U postgres" --health-interval 10s --health-timeout 5s --health-retries 5
      redis:
        image: redis:7-alpine
        ports:
          - 6379:6379
    env:
      SECRET_KEY: ci-secret
      DJANGO_SETTINGS_MODULE: noesis2.settings.development
      DATABASE_URL: postgresql://postgres:postgres@localhost:5432/noesis2_ci
      REDIS_URL: redis://localhost:6379/0
      AI_CORE_TEST_DATABASE_URL: postgresql://postgres:postgres@localhost:5432/postgres
      LANGFUSE_PUBLIC_KEY: ci-public
      LANGFUSE_SECRET_KEY: ci-secret
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}
          cache: "pip"
          cache-dependency-path: |
            requirements.txt
            requirements-dev.txt

      - name: Upgrade pip
        run: python -m pip install --upgrade pip

      - name: Install Python deps
        run: pip install -r requirements.txt -r requirements-dev.txt

      - name: Ensure pgvector extension is available
        run: |
          sudo apt-get update -y && sudo apt-get install -y postgresql-client
          psql "postgresql://postgres:postgres@localhost:5432/postgres" -c "CREATE EXTENSION IF NOT EXISTS vector;" || true

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: "lts/*"
          cache: "npm"
          cache-dependency-path: package-lock.json

      - name: Install Node deps
        run: npm ci

      - name: Run public (shared) migrations
        run: python manage.py migrate_schemas --shared

      - name: Create CI tenant
        run: python manage.py create_tenant --schema=ci --name="CI" --domain=ci.localhost

      - name: Run tenant migrations
        run: python manage.py migrate_schemas --tenant

      - name: Run tests
        run: python -m pytest -q --cov=noesis2 --cov-report=xml

      - name: Upload coverage report
        uses: actions/upload-artifact@v4
        with:
          name: coverage-xml
          path: coverage.xml

  build:
    name: Build and Push Image
    runs-on: ubuntu-latest
    needs: test
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    env:
      REGISTRY_HOST: ${{ secrets.GCP_REGION }}-docker.pkg.dev
      IMAGE: ${{ secrets.GCP_REGION }}-docker.pkg.dev/${{ secrets.GCP_PROJECT_ID }}/${{ secrets.GAR_REPOSITORY }}/noesis2-web:${{ github.sha }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Google Cloud Auth
        uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCP_CREDENTIALS }}

      - name: Set up gcloud SDK
        uses: google-github-actions/setup-gcloud@v2
        with:
          project_id: ${{ secrets.GCP_PROJECT_ID }}

      - name: Configure Docker for Artifact Registry
        run: gcloud auth configure-docker "$REGISTRY_HOST" -q
        env:
          REGISTRY_HOST: ${{ env.REGISTRY_HOST }}

      - name: Build image
        run: docker build -t "$IMAGE" -f Dockerfile .

      - name: Push image
        run: docker push "$IMAGE"

      # Image tag is deterministic (${GITHUB_SHA}); downstream jobs can rebuild it.

  migrate:
    name: Run DB Migrations
    runs-on: ubuntu-latest
    needs: build
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    steps:
      - name: Build DATABASE_URL
        shell: bash
        env:
          DB_USER: ${{ secrets.DB_USER }}
          DB_PASSWORD: ${{ secrets.DB_PASSWORD }}
          DB_NAME: ${{ secrets.DB_NAME }}
        run: |
          enc_pwd=$(python -c "from urllib.parse import quote; import os; print(quote(os.environ['DB_PASSWORD'], safe=''))")
          echo "DATABASE_URL=postgresql://${DB_USER}:${enc_pwd}@/${DB_NAME}" >> "$GITHUB_ENV"
      - name: Google Cloud Auth
        uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCP_CREDENTIALS }}

      - name: Set up gcloud SDK
        uses: google-github-actions/setup-gcloud@v2
        with:
          project_id: ${{ secrets.GCP_PROJECT_ID }}

      - name: Run migrations via Cloud Run Job
        env:
          IMAGE: ${{ secrets.GCP_REGION }}-docker.pkg.dev/${{ secrets.GCP_PROJECT_ID }}/${{ secrets.GAR_REPOSITORY }}/noesis2-web:${{ github.sha }}
          GCP_PROJECT_ID: ${{ secrets.GCP_PROJECT_ID }}
          GCP_REGION: ${{ secrets.GCP_REGION }}
          CLOUD_SQL_CONNECTION_NAME: ${{ secrets.CLOUD_SQL_CONNECTION_NAME }}
          SECRET_KEY: ${{ secrets.SECRET_KEY }}
          REDIS_URL: ${{ secrets.REDIS_URL }}
        run: |
          gcloud run jobs deploy noesis2-migrate \
            --image "$IMAGE" \
            --project "$GCP_PROJECT_ID" \
            --region "$GCP_REGION" \
            --max-retries=0 \
            --task-timeout=600s \
            --set-cloudsql-instances "$CLOUD_SQL_CONNECTION_NAME" \
            --set-env-vars DJANGO_SETTINGS_MODULE=noesis2.settings.production,GOOGLE_CLOUD_PROJECT="$GCP_PROJECT_ID",CLOUD_SQL_CONNECTION_NAME="$CLOUD_SQL_CONNECTION_NAME",SECRET_KEY="$SECRET_KEY",DATABASE_URL="$DATABASE_URL",REDIS_URL="$REDIS_URL" \
            --command python \
            --args manage.py,migrate_schemas,--noinput

  rag-migrate-staging:
    name: RAG Schema Migration (staging)
    runs-on: ubuntu-latest
    needs: migrate
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    steps:
      - name: Build DATABASE_URL
        shell: bash
        env:
          DB_USER: ${{ secrets.DB_USER }}
          DB_PASSWORD: ${{ secrets.DB_PASSWORD }}
          DB_NAME: ${{ secrets.DB_NAME }}
        run: |
          enc_pwd=$(python -c "from urllib.parse import quote; import os; print(quote(os.environ['DB_PASSWORD'], safe=''))")
          echo "DATABASE_URL=postgresql://${DB_USER}:${enc_pwd}@/${DB_NAME}" >> "$GITHUB_ENV"
      - name: Google Cloud Auth
        uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCP_CREDENTIALS }}

      - name: Set up gcloud SDK
        uses: google-github-actions/setup-gcloud@v2
        with:
          project_id: ${{ secrets.GCP_PROJECT_ID }}

      - name: Deploy RAG migrate job
        env:
          IMAGE: ${{ secrets.GCP_REGION }}-docker.pkg.dev/${{ secrets.GCP_PROJECT_ID }}/${{ secrets.GAR_REPOSITORY }}/noesis2-web:${{ github.sha }}
          GCP_PROJECT_ID: ${{ secrets.GCP_PROJECT_ID }}
          GCP_REGION: ${{ secrets.GCP_REGION }}
          CLOUD_SQL_CONNECTION_NAME: ${{ secrets.CLOUD_SQL_CONNECTION_NAME }}
          SECRET_KEY: ${{ secrets.SECRET_KEY }}
          REDIS_URL: ${{ secrets.REDIS_URL }}
        run: |
          gcloud run jobs deploy noesis2-rag-migrate \
            --image "$IMAGE" \
            --project "$GCP_PROJECT_ID" \
            --region "$GCP_REGION" \
            --max-retries=0 \
            --task-timeout=600s \
            --set-cloudsql-instances "$CLOUD_SQL_CONNECTION_NAME" \
            --set-env-vars DJANGO_SETTINGS_MODULE=noesis2.settings.production,GOOGLE_CLOUD_PROJECT="$GCP_PROJECT_ID",CLOUD_SQL_CONNECTION_NAME="$CLOUD_SQL_CONNECTION_NAME",SECRET_KEY="$SECRET_KEY",DATABASE_URL="$DATABASE_URL",REDIS_URL="$REDIS_URL" \
            --command python \
            --args manage.py,apply_rag_schema

      - name: Execute RAG migrate job
        env:
          GCP_PROJECT_ID: ${{ secrets.GCP_PROJECT_ID }}
          GCP_REGION: ${{ secrets.GCP_REGION }}
        run: |
          gcloud run jobs execute noesis2-rag-migrate \
            --project "$GCP_PROJECT_ID" \
            --region "$GCP_REGION" \
            --wait

  seed-staging:
    name: Seed Staging Data
    runs-on: ubuntu-latest
    needs: migrate
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    steps:
      - name: Build DATABASE_URL
        shell: bash
        env:
          DB_USER: ${{ secrets.DB_USER }}
          DB_PASSWORD: ${{ secrets.DB_PASSWORD }}
          DB_NAME: ${{ secrets.DB_NAME }}
        run: |
          enc_pwd=$(python -c "from urllib.parse import quote; import os; print(quote(os.environ['DB_PASSWORD'], safe=''))")
          echo "DATABASE_URL=postgresql://${DB_USER}:${enc_pwd}@/${DB_NAME}" >> "$GITHUB_ENV"
      - name: Checkout
        uses: actions/checkout@v4

      - name: Google Cloud Auth
        uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCP_CREDENTIALS }}

      - name: Set up gcloud SDK
        uses: google-github-actions/setup-gcloud@v2
        with:
          project_id: ${{ secrets.GCP_PROJECT_ID }}

      - name: Seed demo tenant and bind Cloud Run host
        env:
          IMAGE: ${{ secrets.GCP_REGION }}-docker.pkg.dev/${{ secrets.GCP_PROJECT_ID }}/${{ secrets.GAR_REPOSITORY }}/noesis2-web:${{ github.sha }}
          GCP_PROJECT_ID: ${{ secrets.GCP_PROJECT_ID }}
          GCP_REGION: ${{ secrets.GCP_REGION }}
          CLOUD_SQL_CONNECTION_NAME: ${{ secrets.CLOUD_SQL_CONNECTION_NAME }}
          SECRET_KEY: ${{ secrets.SECRET_KEY }}
          REDIS_URL: ${{ secrets.REDIS_URL }}
          STAGING_HOST: ${{ secrets.STAGING_HOST }}
        run: |
          gcloud run jobs deploy noesis2-seed \
            --image "$IMAGE" \
            --project "$GCP_PROJECT_ID" \
            --region "$GCP_REGION" \
            --max-retries=0 \
            --task-timeout=600s \
            --set-cloudsql-instances "$CLOUD_SQL_CONNECTION_NAME" \
            --set-env-vars DJANGO_SETTINGS_MODULE=noesis2.settings.production,GOOGLE_CLOUD_PROJECT="$GCP_PROJECT_ID",CLOUD_SQL_CONNECTION_NAME="$CLOUD_SQL_CONNECTION_NAME",SECRET_KEY="$SECRET_KEY",DATABASE_URL="$DATABASE_URL",REDIS_URL="$REDIS_URL" \
            --command bash \
            --args -lc,"python manage.py bootstrap_public_tenant --domain localhost && python manage.py create_demo_data --domain=\"$STAGING_HOST\""

      - name: Execute seed job
        env:
          GCP_PROJECT_ID: ${{ secrets.GCP_PROJECT_ID }}
          GCP_REGION: ${{ secrets.GCP_REGION }}
        run: |
          gcloud run jobs execute noesis2-seed \
            --project "$GCP_PROJECT_ID" \
            --region "$GCP_REGION" \
            --wait
          gcloud run jobs execute noesis2-migrate --project "$GCP_PROJECT_ID" --region "$GCP_REGION" --wait

  deploy-staging:
    name: Deploy to Cloud Run (staging)
    runs-on: ubuntu-latest
    needs: rag-migrate-staging
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    env:
      IMAGE: ${{ secrets.GCP_REGION }}-docker.pkg.dev/${{ secrets.GCP_PROJECT_ID }}/${{ secrets.GAR_REPOSITORY }}/noesis2-web:${{ github.sha }}
    steps:
      - name: Build DATABASE_URL
        shell: bash
        env:
          DB_USER: ${{ secrets.DB_USER }}
          DB_PASSWORD: ${{ secrets.DB_PASSWORD }}
          DB_NAME: ${{ secrets.DB_NAME }}
        run: |
          enc_pwd=$(python -c "from urllib.parse import quote; import os; print(quote(os.environ['DB_PASSWORD'], safe=''))")
          echo "DATABASE_URL=postgresql://${DB_USER}:${enc_pwd}@/${DB_NAME}" >> "$GITHUB_ENV"
      - name: Google Cloud Auth
        uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCP_CREDENTIALS }}

      - name: Set up gcloud SDK
        uses: google-github-actions/setup-gcloud@v2
        with:
          project_id: ${{ secrets.GCP_PROJECT_ID }}

      - name: Deploy to Cloud Run (staging)
        uses: google-github-actions/deploy-cloudrun@v2.1.0
        with:
          service: noesis-2-staging
          image: ${{ env.IMAGE }}
          project_id: ${{ secrets.GCP_PROJECT_ID }}
          region: ${{ secrets.GCP_REGION }}
          flags: '--add-cloudsql-instances=${{ secrets.CLOUD_SQL_CONNECTION_NAME }} --allow-unauthenticated'
          env_vars: |
            DJANGO_SETTINGS_MODULE=noesis2.settings.production
            GOOGLE_CLOUD_PROJECT=${{ secrets.GCP_PROJECT_ID }}
            CLOUD_SQL_CONNECTION_NAME=${{ secrets.CLOUD_SQL_CONNECTION_NAME }}
            SECRET_KEY=${{ secrets.SECRET_KEY }}
            DATABASE_URL=${{ env.DATABASE_URL }}
            REDIS_URL=${{ secrets.REDIS_URL }}

  smoke-staging:
    name: Smoke Test (staging)
    runs-on: ubuntu-latest
    needs: deploy-staging
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    steps:
      - name: Google Cloud Auth
        uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCP_CREDENTIALS }}

      - name: Set up gcloud SDK
        uses: google-github-actions/setup-gcloud@v2
        with:
          project_id: ${{ secrets.GCP_PROJECT_ID }}

      - name: Resolve service URL
        id: svc
        env:
          GCP_PROJECT_ID: ${{ secrets.GCP_PROJECT_ID }}
          GCP_REGION: ${{ secrets.GCP_REGION }}
        run: |
          URL=$(gcloud run services describe noesis-2-staging \
            --project "$GCP_PROJECT_ID" --region "$GCP_REGION" \
            --format='value(status.url)')
          echo "url=$URL" >> "$GITHUB_OUTPUT"

      - name: Ping /ai/ping/
        env:
          URL: ${{ steps.svc.outputs.url }}
        run: |
          echo "Pinging: ${URL}/ai/ping/"
          curl -fsSI -H 'X-Tenant-Schema: demo' -H 'X-Tenant-ID: demo-tenant' -H 'X-Case-ID: smoke' "$URL/ai/ping/" | head -n 1

      - name: POST /ai/scope
        env:
          URL: ${{ steps.svc.outputs.url }}
        run: |
          curl -fsS -X POST \
            -H 'Content-Type: application/json' \
            -H 'X-Tenant-Schema: demo' -H 'X-Tenant-ID: demo-tenant' -H 'X-Case-ID: smoke' \
            --data '{"hello":"world"}' \
            "$URL/ai/scope/" | head -c 200; echo

  deploy-worker-staging:
    name: Deploy Worker (staging) [disabled; moving to GKE]
    runs-on: ubuntu-latest
    needs: rag-migrate-staging
    if: false
    env:
      IMAGE: ${{ secrets.GCP_REGION }}-docker.pkg.dev/${{ secrets.GCP_PROJECT_ID }}/${{ secrets.GAR_REPOSITORY }}/noesis2-web:${{ github.sha }}
    steps:
      - name: Build DATABASE_URL
        shell: bash
        env:
          DB_USER: ${{ secrets.DB_USER }}
          DB_PASSWORD: ${{ secrets.DB_PASSWORD }}
          DB_NAME: ${{ secrets.DB_NAME }}
        run: |
          enc_pwd=$(python -c "from urllib.parse import quote; import os; print(quote(os.environ['DB_PASSWORD'], safe=''))")
          echo "DATABASE_URL=postgresql://${DB_USER}:${enc_pwd}@/${DB_NAME}" >> "$GITHUB_ENV"
      - name: Google Cloud Auth
        uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCP_CREDENTIALS }}

      - name: Set up gcloud SDK
        uses: google-github-actions/setup-gcloud@v2
        with:
          project_id: ${{ secrets.GCP_PROJECT_ID }}

      - name: Deploy Worker service (staging)
        uses: google-github-actions/deploy-cloudrun@v2.1.0
        with:
          service: noesis-2-worker-staging
          image: ${{ env.IMAGE }}
          project_id: ${{ secrets.GCP_PROJECT_ID }}
          region: ${{ secrets.GCP_REGION }}
          flags: >-
            --add-cloudsql-instances=${{ secrets.CLOUD_SQL_CONNECTION_NAME }}
            --allow-unauthenticated
            --command=bash
            --args="-lc,python -m noesis2.healthsrv & celery -A noesis2 worker -l info"
          env_vars: |
            DJANGO_SETTINGS_MODULE=noesis2.settings.production
            GOOGLE_CLOUD_PROJECT=${{ secrets.GCP_PROJECT_ID }}
            CLOUD_SQL_CONNECTION_NAME=${{ secrets.CLOUD_SQL_CONNECTION_NAME }}
            SECRET_KEY=${{ secrets.SECRET_KEY }}
            DATABASE_URL=${{ env.DATABASE_URL }}
            REDIS_URL=${{ secrets.REDIS_URL }}
          # Note: Cloud SQL attachment is handled via flags; no metadata YAML.

  deploy-beat-staging:
    name: Deploy Beat (staging) [disabled; moving to GKE]
    runs-on: ubuntu-latest
    needs: rag-migrate-staging
    if: false
    env:
      IMAGE: ${{ secrets.GCP_REGION }}-docker.pkg.dev/${{ secrets.GCP_PROJECT_ID }}/${{ secrets.GAR_REPOSITORY }}/noesis2-web:${{ github.sha }}
    steps:
      - name: Google Cloud Auth
        uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCP_CREDENTIALS }}

      - name: Set up gcloud SDK
        uses: google-github-actions/setup-gcloud@v2
        with:
          project_id: ${{ secrets.GCP_PROJECT_ID }}

      - name: Deploy Beat service (staging)
        uses: google-github-actions/deploy-cloudrun@v2.1.0
        with:
          service: noesis-2-beat-staging
          image: ${{ env.IMAGE }}
          project_id: ${{ secrets.GCP_PROJECT_ID }}
          region: ${{ secrets.GCP_REGION }}
          flags: >-
            --add-cloudsql-instances=${{ secrets.CLOUD_SQL_CONNECTION_NAME }}
            --allow-unauthenticated
            --command=bash
            --args="-lc,python -m noesis2.healthsrv & celery -A noesis2 beat -l info"
          env_vars: |
            DJANGO_SETTINGS_MODULE=noesis2.settings.production
            GOOGLE_CLOUD_PROJECT=${{ secrets.GCP_PROJECT_ID }}
            CLOUD_SQL_CONNECTION_NAME=${{ secrets.CLOUD_SQL_CONNECTION_NAME }}
            SECRET_KEY=${{ secrets.SECRET_KEY }}
            DATABASE_URL=${{ env.DATABASE_URL }}
            REDIS_URL=${{ secrets.REDIS_URL }}
          # Note: Cloud SQL attachment is handled via flags; no metadata YAML.

  deploy-litellm-staging:
    name: Deploy LiteLLM (staging)
    runs-on: ubuntu-latest
    needs: deploy-staging
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    steps:
      - name: Build LITELLM_DATABASE_URL
        shell: bash
        env:
          DB_USER: ${{ secrets.DB_USER }}
          DB_PASSWORD: ${{ secrets.DB_PASSWORD }}
          LITELLM_DB_NAME: ${{ secrets.LITELLM_DB_NAME }}
          CLOUD_SQL_CONNECTION_NAME: ${{ secrets.CLOUD_SQL_CONNECTION_NAME }}
        run: |
          : "${LITELLM_DB_NAME:=litellm}"
          enc_pwd=$(python -c "from urllib.parse import quote; import os; print(quote(os.environ['DB_PASSWORD'], safe=''))")
          LITELLM_DATABASE_URL="postgresql://${DB_USER}:${enc_pwd}@/${LITELLM_DB_NAME}?host=/cloudsql/${CLOUD_SQL_CONNECTION_NAME}&connect_timeout=60"
          echo "[diag] Encoded DB_PASSWORD: ${enc_pwd}"
          echo "[diag] LITELLM_DATABASE_URL (FULL): ${LITELLM_DATABASE_URL}"
          echo "LITELLM_DATABASE_URL=${LITELLM_DATABASE_URL}" >> "$GITHUB_ENV"
      - name: Google Cloud Auth
        uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCP_CREDENTIALS }}

      - name: Set up gcloud SDK
        uses: google-github-actions/setup-gcloud@v2
        with:
          project_id: ${{ secrets.GCP_PROJECT_ID }}

      - name: Ensure LiteLLM database exists (Cloud SQL)
        shell: bash
        env:
          CLOUD_SQL_CONNECTION_NAME: ${{ secrets.CLOUD_SQL_CONNECTION_NAME }}
          LITELLM_DB_NAME: ${{ secrets.LITELLM_DB_NAME }}
        run: |
          : "${LITELLM_DB_NAME:=litellm}"
          INSTANCE=${CLOUD_SQL_CONNECTION_NAME##*:}
          echo "Ensuring DB '$LITELLM_DB_NAME' exists on instance '$INSTANCE'"
          gcloud sql databases describe "$LITELLM_DB_NAME" --instance "$INSTANCE" --project ${{ secrets.GCP_PROJECT_ID }} >/dev/null 2>&1 \
            || gcloud sql databases create "$LITELLM_DB_NAME" --instance "$INSTANCE" --project ${{ secrets.GCP_PROJECT_ID }}

      - name: Mirror LiteLLM image to Artifact Registry
        env:
          AR_IMAGE: ${{ secrets.GCP_REGION }}-docker.pkg.dev/${{ secrets.GCP_PROJECT_ID }}/${{ secrets.GAR_REPOSITORY }}/litellm:main-stable
        run: |
          gcloud auth configure-docker ${{ secrets.GCP_REGION }}-docker.pkg.dev -q
          docker pull ghcr.io/berriai/litellm:main-stable
          docker tag ghcr.io/berriai/litellm:main-stable "$AR_IMAGE"
          docker push "$AR_IMAGE"
          echo "LITELLM_AR_IMAGE=$AR_IMAGE" >> "$GITHUB_ENV"

      - name: Deploy LiteLLM service (DIAGNOSTIC MODE)
        env:
          IMAGE: ${{ env.LITELLM_AR_IMAGE }}
          GCP_PROJECT_ID: ${{ secrets.GCP_PROJECT_ID }}
          GCP_REGION: ${{ secrets.GCP_REGION }}
          CLOUD_SQL_CONNECTION_NAME: ${{ secrets.CLOUD_SQL_CONNECTION_NAME }}
          LITELLM_MASTER_KEY: ${{ secrets.LITELLM_MASTER_KEY }}
          LITELLM_SALT_KEY: ${{ secrets.LITELLM_SALT_KEY }}
          UI_USERNAME: ${{ secrets.LITELLM_UI_USERNAME }}
          UI_PASSWORD: ${{ secrets.LITELLM_UI_PASSWORD }}
          GOOGLE_API_KEY: ${{ secrets.GOOGLE_API_KEY }}
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
        run: |
          set -euo pipefail
          # Build a JSON env file to safely pass secrets (supports any characters)
          python -c "import json, os; data={'LITELLM_MASTER_KEY': os.environ.get('LITELLM_MASTER_KEY',''), 'LITELLM_SALT_KEY': os.environ.get('LITELLM_SALT_KEY',''), 'DATABASE_URL': os.environ.get('LITELLM_DATABASE_URL',''), 'UI_USERNAME': os.environ.get('UI_USERNAME',''), 'UI_PASSWORD': os.environ.get('UI_PASSWORD',''), 'GOOGLE_API_KEY': os.environ.get('GOOGLE_API_KEY',''), 'GEMINI_API_KEY': os.environ.get('GEMINI_API_KEY','')}; json.dump(data, open('env.litellm.json','w'))"

          gcloud run deploy litellm-staging \
            --image "${IMAGE}" \
            --project "${GCP_PROJECT_ID}" \
            --region "${GCP_REGION}" \
            --allow-unauthenticated \
            --add-cloudsql-instances "${CLOUD_SQL_CONNECTION_NAME}" \
            --cpu 1 \
            --memory 2Gi \
            --cpu-boost \
            --timeout 600s \
            --min-instances 1 \
            --port 4000 \
            --env-vars-file env.litellm.json \
            --command python \
            --args="-m,http.server,4000"
          
  deploy-gke-workers:
    name: Deploy Workers to GKE
    runs-on: ubuntu-latest
    needs: build
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Google Cloud Auth
        uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCP_CREDENTIALS }}

      - name: Set up gcloud SDK
        uses: google-github-actions/setup-gcloud@v2
        with:
          project_id: ${{ secrets.GCP_PROJECT_ID }}

      - name: Get GKE credentials
        uses: google-github-actions/get-gke-credentials@v2
        with:
          cluster_name: ${{ secrets.GKE_CLUSTER_NAME }}
          location: ${{ secrets.GKE_LOCATION }}

      - name: Create namespace & SA (idempotent)
        run: |
          kubectl apply -f k8s/namespace.yaml
          kubectl apply -f k8s/serviceaccount.yaml

      - name: Create/Update app-secrets from GitHub Secrets
        env:
          SECRET_KEY: ${{ secrets.SECRET_KEY }}
          DB_USER: ${{ secrets.DB_USER }}
          DB_PASSWORD: ${{ secrets.DB_PASSWORD }}
          DB_NAME: ${{ secrets.DB_NAME }}
          REDIS_URL: ${{ secrets.REDIS_URL }}
        run: |
          enc_pwd=$(python -c "from urllib.parse import quote; import os; print(quote(os.environ['DB_PASSWORD'], safe=''))")
          kubectl create secret generic app-secrets \
            -n noesis2 \
            --from-literal=SECRET_KEY="$SECRET_KEY" \
            --from-literal=DB_USER="$DB_USER" \
            --from-literal=DB_PASSWORD="$DB_PASSWORD" \
            --from-literal=DATABASE_URL="postgresql://${DB_USER}:${enc_pwd}@127.0.0.1:5432/${DB_NAME}" \
            --from-literal=REDIS_URL="$REDIS_URL" \
            --dry-run=client -o yaml | kubectl apply -f -

      - name: Apply worker/beat manifests
        env:
          IMAGE: ${{ secrets.GCP_REGION }}-docker.pkg.dev/${{ secrets.GCP_PROJECT_ID }}/${{ secrets.GAR_REPOSITORY }}/noesis2-web:${{ github.sha }}
          PROJECT: ${{ secrets.GCP_PROJECT_ID }}
          REGION: ${{ secrets.GCP_REGION }}
          INSTANCE: ${{ secrets.CLOUD_SQL_CONNECTION_NAME }}
        run: |
          sed -e "s#REGION-docker.pkg.dev/PROJECT/REPO/noesis2-web:SHA#${IMAGE}#g" \
              -e "s#PROJECT:REGION:INSTANCE#${INSTANCE}#g" \
              k8s/worker-deployment.yaml | kubectl apply -f -
          sed -e "s#REGION-docker.pkg.dev/PROJECT/REPO/noesis2-web:SHA#${IMAGE}#g" \
              -e "s#PROJECT:REGION:INSTANCE#${INSTANCE}#g" \
              k8s/beat-deployment.yaml | kubectl apply -f -
          kubectl apply -f k8s/worker-hpa.yaml

      - name: Wait for rollouts (with diagnostics)
        run: |
          set +e
          kubectl rollout status deploy/celery-worker -n noesis2 --timeout=300s
          STATUS=$?
          if [ $STATUS -ne 0 ]; then
            echo "Worker rollout failed; collecting diagnostics"
            kubectl get pods -n noesis2 -o wide
            kubectl describe deploy/celery-worker -n noesis2 || true
            kubectl describe pods -n noesis2 -l app=celery-worker || true
            kubectl logs -n noesis2 deploy/celery-worker --all-containers --tail=200 || true
            exit $STATUS
          fi
          kubectl rollout status deploy/celery-beat -n noesis2 --timeout=300s
          STATUS=$?
          if [ $STATUS -ne 0 ]; then
            echo "Beat rollout failed; collecting diagnostics"
            kubectl get pods -n noesis2 -o wide
            kubectl describe deploy/celery-beat -n noesis2 || true
            kubectl describe pods -n noesis2 -l app=celery-beat || true
            kubectl logs -n noesis2 deploy/celery-beat --all-containers --tail=200 || true
            exit $STATUS
          fi




