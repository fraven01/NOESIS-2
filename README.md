# NOESIS 2

## Vision
KI-gestÃ¼tzte SaaS-Plattform zur prozessualen UnterstÃ¼tzung der betrieblichen Mitbestimmung nach Â§ 87 Abs. 1 Nr. 6 BetrVG.

> ðŸ“˜ **Zentrale Leitplanken & Navigation:** [AGENTS.md](AGENTS.md) bÃ¼ndelt Rollen, Trigger und Links zu allen PrimÃ¤rquellen.
>
> ðŸš€ **Neu im Projekt?** Der [Onboarding-Leitfaden](docs/development/onboarding.md) fÃ¼hrt Schritt fÃ¼r Schritt durch Setup, Skripte und weiterfÃ¼hrende Dokumentation.

## Kernfunktionen (Geplant)
- Flexible, workflow-basierte Analyse von Dokumenten (z. B. Systembeschreibungen, Betriebsvereinbarungen)
- MandantenfÃ¤higkeit zur Trennung von Daten verschiedener Parteien (Arbeitgeber, BetriebsrÃ¤te, AnwÃ¤lte)
- Wissensgenerierung und -abfrage durch angebundene Large Language Models (LLMs)
- Asynchrone Verarbeitung von rechenintensiven Analyse-Aufgaben

---

## Technologie-Stack
- Backend: Python 3.12+ mit Django 5.x
- Asynchrone Tasks: Celery & Redis
- Datenbank: PostgreSQL
- Frontend: Tailwind CSS v4 (PostCSS)
- Entwicklungsumgebung: Node.js, npm
- CI/CD & Testing: GitHub Actions, pytest

## AI Core

### API-Endpunkte
Alle Pfade erfordern die Header `X-Tenant-ID`, `X-Case-ID` sowie `Idempotency-Key`. Antworten enthalten Standard-Trace-Header und optionale `gaps` oder `citations`. Der `Idempotency-Key` muss pro Mandant und Vorgang eindeutig sein, damit wiederholte POST-Aufrufe dedupliziert werden kÃ¶nnen.

- `GET /ai/ping/` â€“ einfacher Health-Check
- `POST /ai/intake/` â€“ Metadaten speichern und EingangsbestÃ¤tigung liefern
- `POST /ai/scope/` â€“ Auftragsumfang prÃ¼fen und fehlende Angaben melden
- `POST /ai/needs/` â€“ Informationen dem Tenant-Profil zuordnen, Abbruch bei LÃ¼cken
- `POST /ai/sysdesc/` â€“ Systembeschreibung nur wenn keine Informationen fehlen

### Graphen
Die Views orchestrieren reine Python-Graphen. Jeder Graph erhÃ¤lt `state: dict` und `meta: {tenant, case, trace_id}` und gibt `(new_state, result)` zurÃ¼ck. Der Zustand wird nach jedem Schritt in `.ai_core_store/{tenant}/{case}/state.json` persistiert. Gates wie `needs_mapping` oder `scope_check` brechen frÃ¼h ab, statt unvollstÃ¤ndige Drafts zu erzeugen.

### Lokale Nutzung
Das bestehende `docker compose`-Setup startet Web-App und Redis. Ein externer LiteLLM-Proxy kann Ã¼ber `LITELLM_BASE_URL` angebunden werden. Nach dem Start (`docker compose ... up`) kÃ¶nnen die Endpunkte lokal unter `http://localhost:8000/ai/` getestet werden.

### PII-Scope Playbook
Der Session-Scope sorgt dafÃ¼r, dass dieselben deterministischen Platzhalter in Requests, LLM-Aufrufen, Logs und Tasks genutzt werden. Das Playbook [docs/pii-scope.md](docs/pii-scope.md) beschreibt die Reihenfolge (Middleware â†’ Masking â†’ Logging â†’ Tasks â†’ Egress), enthÃ¤lt eine Review-Checkliste und eine FastAPI-Referenz fÃ¼r Microservices.

---

## Docker Quickstart
```bash
# Falls noch keine .env vorhanden ist:
# Windows: copy .env.example .env   |   Linux/macOS: cp .env.example .env

docker compose -f docker-compose.yml -f docker-compose.dev.yml build
docker compose -f docker-compose.yml -f docker-compose.dev.yml up -d

# Bootstrap & Checks (idempotent):
npm run dev:up
npm run dev:check
```

Hinweise:
- Wenn bereits eine lokale `.env` mit gÃ¼ltigen SchlÃ¼sseln existiert, Kopierschritt Ã¼berspringen.
- Der Entwicklungscontainer fÃ¼hrt `python manage.py collectstatic` beim Start automatisch aus.
- Bei Ã¤lteren Compose-Setups ggf. manuell:
  `docker-compose exec web python manage.py collectstatic` (notwendig wegen `CompressedManifestStaticFilesStorage`).

---

## Lokales Setup (Alternative ohne Docker)

Docker Compose ist die bevorzugte Methode fÃ¼r ein konsistentes, schnelles Setup.
Die folgenden Schritte sind ein manueller Fallback, falls Docker nicht genutzt wird.

### Voraussetzungen
- Python 3.12+
- Node.js und npm
- PostgreSQL-Server
- Redis-Server

### Installations-Schritte
1. Repository klonen
   ```bash
   git clone https://github.com/fraven01/NOESIS-2.git
   cd NOESIS-2
   ```
2. Python-Umgebung einrichten
   ```bash
   python -m venv .venv
   # Linux/macOS
   source .venv/bin/activate
   # Windows PowerShell
   .\.venv\Scripts\Activate.ps1

   pip install -r requirements.txt
   pip install -r requirements-dev.txt
   ```
3. Frontend-AbhÃ¤ngigkeiten installieren
   ```bash
   npm install
   ```
4. Datenbank einrichten
   - Leere PostgreSQL-Datenbank erstellen (z. B. `CREATE DATABASE noesis2_db;`).
   - `.env.example` nach `.env` kopieren und Zugangsdaten anpassen.
   - Migrationen ausfÃ¼hren:
     ```bash
     python manage.py migrate
     ```
5. Superuser anlegen
   ```bash
   python manage.py createsuperuser
   ```

### Entwicklungsserver starten
```bash
npm run dev
```


## Lokales Testen

Die Tests greifen auf die in `docker-compose.dev.yml` definierten Service-Hosts (u. a. `db`) zu. Ausserhalb der Compose-Umgebung fehlen diese Namensaufloesungen und Django bricht mit Verbindungsfehlern ab. Zudem enthaelt das `web`-Image nur Produktionsabhaengigkeiten, daher muessen vor dem Testlauf sowohl Basis- als auch Dev-Abhaengigkeiten installiert werden.

```bash
docker compose -f docker-compose.dev.yml run --rm web sh -c "pip install -r requirements.txt -r requirements-dev.txt && python -m pytest"
```

Der Befehl laedt die benoetigten Pakete in den temporaeren Container, fuehrt die Tests aus und entfernt den Container anschliessend wieder. Fuehre ihn bei jedem frischen Containerlauf erneut aus, da Installationen nicht persistent sind.

## Anwendung ausfÃ¼hren mit Docker

- `docker compose -f docker-compose.yml -f docker-compose.dev.yml up`: Startet die gesamte Anwendung im Vordergrund (Logs im Terminal).
- `docker compose -f docker-compose.yml -f docker-compose.dev.yml up -d`: Startet die Anwendung im Hintergrund (detached mode).
- `docker compose -f docker-compose.yml -f docker-compose.dev.yml down`: Stoppt und entfernt die Container (Volumes wie Datenbankdaten bleiben erhalten).
- `npm run dev:manage <befehl>`: FÃ¼hrt einen `manage.py`-Befehl (z. B. `createsuperuser`) im laufenden `web`-Container aus (Windows: `npm run win:dev:manage <befehl>`).
- Der Entwicklungscontainer fÃ¼hrt `python manage.py collectstatic` beim Start automatisch aus.
  Bei Ã¤lteren Compose-Setups muss dieser Schritt manuell erfolgen:
  `docker-compose exec web python manage.py collectstatic`.
  Notwendig, da `CompressedManifestStaticFilesStorage` aktiv ist.
- Hinweis zu `.env`: Host-seitige Werte fÃ¼r `DATABASE_URL`/`REDIS_URL` bleiben fÃ¼r lokale Tools bestehen.
  Die Compose-Services `web` und `worker` lesen stattdessen `.env.docker` (Standardwerte sind
  `postgresql://noesis2:noesis2@db:5432/noesis2` bzw. `redis://redis:6379/0`).
  Passe Container-DSNs bei Bedarf Ã¼ber `COMPOSE_DATABASE_URL`/`COMPOSE_REDIS_URL` in `.env.docker`
  oder Ã¼berschreibe sie gezielt in deiner `.env`.
- Datenbankmigrationen laufen nicht automatisch mit. FÃ¼hre sie bei Bedarf manuell aus, z.â€¯B. mit
  `npm run dev:manage migrate`.

### Dev-Skripte (idempotent)
- `npm run dev:up`: Startet/initialisiert die Umgebung, fÃ¼hrt `migrate_schemas`, bootstrapped den Publicâ€‘Tenant, legt `dev`â€‘Tenant und Superuser an.
- `npm run dev:check`: FÃ¼hrt Smokeâ€‘Checks aus (LiteLLM Health/Chat, `GET /ai/ping/`, `POST /ai/scope/`). Chat erfordert gÃ¼ltige `GEMINI_API_KEY`.
- `npm run dev:down`: Stoppt und entfernt alle Container inkl. Volumes.
- `npm run dev:rebuild`: Baut Web- und Worker-Images neu und aktualisiert Code-AbhÃ¤ngigkeiten, ohne Volumes zu lÃ¶schen. Mit `npm run dev:rebuild -- --with-frontend` lÃ¤sst sich optional auch das Frontend-Image aktualisieren.
- `npm run dev:restart`: Startet Web- und Worker-Container schnell neu (Compose `restart`).
- `npm run dev:manage <befehl>`: Wrapper fÃ¼r `python manage.py` im Web-Container (z.â€¯B. `npm run dev:manage makemigrations users`).
- `npm run dev:init`: FÃ¼hrt die Composeâ€‘Jobs `migrate` und `bootstrap` aus (nach `up -d`).
- `npm run dev:reset`: Full reset (down -v â†’ build --no-cache â†’ up -d â†’ init â†’ checks).
- `npm run jobs:rag`: FÃ¼hrt `docs/rag/schema.sql` gegen die DB aus (idempotent).
- `npm run rag:enable`: Setzt `RAG_ENABLED=true` in `.env` und startet Web/Worker neu.
 - `npm run jobs:rag:health`: PrÃ¼ft RAG-Gesundheit (pgvector installiert, Tabellen vorhanden).

**Wann welches Skript?**
- Konfigurationswerte, Feature-Flags oder Django-Code geÃ¤ndert und die laufenden Container sollen die Ã„nderungen aufnehmen â†’ `npm run dev:restart` (Windows: `npm run win:dev:restart`).
- Neue Python-/Node-AbhÃ¤ngigkeiten installiert oder das Dockerfile angepasst â†’ `npm run dev:rebuild` (Windows: `npm run win:dev:rebuild`).
- Komplettes Setup inkl. Datenbanken zurÃ¼cksetzen (z.â€¯B. nach kaputten Fixtures) â†’ `npm run dev:reset` (Windows: `npm run win:dev:reset`).
- Nur das RAG-Schema aktualisieren bzw. die Installation verifizieren â†’ `npm run jobs:rag` bzw. `npm run jobs:rag:health`.
- Demo-Tenant & Beispieldaten neu befÃ¼llen â†’ `npm run dev:manage create_demo_data` (Windows: `npm run win:dev:manage create_demo_data`).

Hinweis (Windows): PowerShellâ€‘Varianten sind enthalten:
- `npm run win:dev:up`
- `npm run win:dev:check`
- `npm run win:dev:down`
- `npm run win:dev:rebuild` (optional mit `npm run win:dev:rebuild -- -WithFrontend`)
- `npm run win:dev:restart`
- `npm run win:dev:manage <befehl>`
- `npm run win:dev:reset`
- `npm run win:rag:enable`
- `npm run win:jobs:rag`
- `npm run win:jobs:rag:health`

### Git Hooks (Lint vor Push)
- Installieren: 
  - macOS/Linux: `npm run hooks:install`
  - Windows: `npm run win:hooks:install`
- Wirkung: Vor jedem `git push` lÃ¤uft automatisch `npm run lint` (ruff + black). Zum Ãœberspringen einmalig `SKIP_LINT=1 git push` setzen.

---
 
## Konfiguration (.env)
BenÃ¶tigte Variablen (siehe `.env.example` oder `.env.dev.sample`):

- SECRET_KEY: geheimer SchlÃ¼ssel fÃ¼r Django
- DEBUG: `true`/`false`
- DB_USER / DB_PASSWORD / DB_NAME: gemeinsame Devâ€‘Credentials; werden fÃ¼r den Containerâ€‘Init und DSNs genutzt.
- DATABASE_URL: Verbindungs-URL zur PostgreSQL-Datenbank (Appâ€‘DB, default: `postgresql://noesis2:noesis2@db:5432/noesis2`)
- REDIS_URL: Redis-Endpoint (z. B. fÃ¼r Celery)
- RAG_ENABLED: `true`/`false` zur Aktivierung des Retrieval-Augmented-Generation-Workflows.
  Aktiviere das Flag nur, wenn das `rag`-Schema inklusive `pgvector`-Extension (`CREATE EXTENSION IF NOT EXISTS vector;`)
  anhand von [`docs/rag/schema.sql`](docs/rag/schema.sql) bereitsteht und Ã¼ber `DATABASE_URL` oder `RAG_DATABASE_URL`
  erreichbar ist. FÃ¼r den Datenbankzugriff wird `psycopg2` (oder das BinÃ¤r-Pendant `psycopg2-binary`) benÃ¶tigt.
  Achtung: Mandanten-IDs mÃ¼ssen UUIDs sein. Ã„ltere nicht-UUID-Werte werden deterministisch gemappt, sollten aber per Migration
  bereinigt werden, bevor Deployments `RAG_ENABLED=true` setzen.

AI Core:
- LITELLM_BASE_URL: Basis-URL des LiteLLM-Proxys
- LITELLM_API_KEY: API-Key fÃ¼r den Proxy
- LITELLM_DATABASE_URL (optional): separates DBâ€‘DSN fÃ¼r die LiteLLM Adminâ€‘DB (default in Compose aus `DB_*` + `LITELLM_DB_NAME`)
- LANGFUSE_PUBLIC_KEY / LANGFUSE_SECRET_KEY: SchlÃ¼ssel fÃ¼r Langfuse-Tracing
- LITELLM_SALT_KEY: Salt fÃ¼r VerschlÃ¼sselung gespeicherter Providerâ€‘Keys in der Adminâ€‘DB (empfohlen fÃ¼r Admin UI)

Die Settings lesen `.env` via `django-environ`. `DATABASE_URL` muss eine vollstÃ¤ndige URL enthalten (inkl. URL-Encoding fÃ¼r Sonderzeichen); `REDIS_URL` wird sowohl fÃ¼r Celery als auch fÃ¼r Redis-basierte Integrationen verwendet.

Best Practice: In Dev einen gemeinsamen DBâ€‘User fÃ¼r App und LiteLLM verwenden (einfachere Einrichtung). In Produktion getrennte Rollen/DSNs je Dienst (Least Privilege).

## LiteLLM & Modelle (Prod vs. Lokal)
- Produktion (Cloud Run)
  - LiteLLM authentifiziert gegen Vertex AI per Service Account (ADC), kein APIâ€‘Key nÃ¶tig.
  - Regionensplit: Cloud Run `europe-west3`, Vertex `us-central1` (siehe `scripts/init_litellm_gcloud.sh` und CI).
  - Routing: `MODEL_ROUTING.yaml` zeigt auf `vertex_ai/*` Modelle (z. B. `vertex_ai/gemini-2.5-flash`).
  - Labels â†’ Modelle (Vertex AI):
    - `default`, `fast`, `simple-query`, `synthesize`, `extract`, `classify`, `analyze` â†’ `vertex_ai/gemini-2.5-flash`
    - `reasoning`, `draft` â†’ `vertex_ai/gemini-2.5-pro`
    - `embedding` â†’ `vertex_ai/text-embedding-004`
  - CI setzt `VERTEXAI_PROJECT` und `VERTEXAI_LOCATION` und pinned die Cloudâ€‘Run Serviceâ€‘Accountâ€‘IdentitÃ¤t.

- Lokal (Docker Compose)
  - Vertex ADC steht lokal i. d. R. nicht zur VerfÃ¼gung. Nutze AIâ€‘Studio (Gemini) Ã¼ber LiteLLMâ€‘Config.
  - Datei `config/litellm-config.yaml` ist fÃ¼r AIâ€‘Studio konfiguriert (`gemini/*` + `GEMINI_API_KEY`).
  - Erzeuge eine lokale Routingâ€‘Override, damit Django lokale Modelle anspricht:
    ```bash
    cp MODEL_ROUTING.local.yaml.sample MODEL_ROUTING.local.yaml
    ```
  - Setze in `.env` mindestens:
    - `GEMINI_API_KEY=<dein_ai_studio_key>`
    - `LITELLM_MASTER_KEY=<beliebiger_dev_key>`
  - Starte LiteLLM via Compose und teste:
    ```bash
    docker compose -f docker-compose.yml -f docker-compose.dev.yml up -d litellm
    bash scripts/smoke_litellm.sh
    ```

  - Labels â†’ Modelle (AI Studio):
    - `default`, `fast`, `simple-query`, `synthesize`, `extract`, `classify`, `analyze` â†’ `gemini-2.5-flash`
    - `reasoning`, `draft` â†’ `gemini-2.5-pro`
    - `embedding` â†’ `google/text-embedding-004`

Hinweis: `MODEL_ROUTING.local.yaml` ist gitâ€‘ignored und Ã¼berschreibt nur lokal. In Prod wird ausschlieÃŸlich `MODEL_ROUTING.yaml` verwendet.

## GCloud Bootstrap (Windows)
Mit dem Skript `scripts/gcloud-bootstrap.ps1` kannst du dich per `gcloud` anmelden, ein Projekt/Region wÃ¤hlen und hÃ¤ufige Laufzeitwerte aus GCP sammeln (Redis, Cloud SQL, Cloud Run URLs). Die Werte werden sicher in `.env.gcloud` geschrieben (Git-ignored) und kÃ¶nnen selektiv in deine `.env` Ã¼bernommen werden.

PowerShell (Windows):

```powershell
pwsh -File scripts/gcloud-bootstrap.ps1
# oder nicht-interaktiv mit Vorgaben:
pwsh -File scripts/gcloud-bootstrap.ps1 -Region europe-west3 -Zone europe-west3-a

# Optional: Secrets explizit ziehen (schreibt sensible Werte in .env.gcloud!)
pwsh -File scripts/gcloud-bootstrap.ps1 -FetchSecrets -Secrets SECRET_KEY,LANGFUSE_KEY
```

Hinweise:
- Secrets werden standardmÃ¤ÃŸig nicht geladen. Mit `-FetchSecrets` + `-Secrets` kannst du gezielt Secret-Names laden, sofern dein Account berechtigt ist.
- FÃ¼r Cloud SQL im lokalen Setup bevorzugen wir weiterhin die lokale DB (Docker). Alternativ Cloud SQL Auth Proxy verwenden und `DB_HOST`/`DATABASE_URL` passend setzen.

## GCloud Bootstrap (Bash/WSL/Linux)
Das Bash-Pendant lÃ¤uft unter WSL oder Linux. Es sammelt dieselben Werte und schreibt `.env.gcloud` (Git-ignored).

```bash
# Interaktiv
bash scripts/gcloud-bootstrap.sh

# Mit Parametern
bash scripts/gcloud-bootstrap.sh --region europe-west3 --zone europe-west3-a

# Optional Secrets (vorsichtig)
bash scripts/gcloud-bootstrap.sh --fetch-secrets \
  --secret SECRET_KEY --secret LANGFUSE_KEY
```

Voraussetzungen: `gcloud` im PATH. `jq` ist nicht erforderlich.

## Settings-Profile
Das alte `noesis2/settings.py` wurde entfernt; verwende ausschlieÃŸlich das modulare Paket `noesis2/settings/`.

- Standard: `noesis2.settings.development` (in `manage.py`, `asgi.py`, `wsgi.py` vorkonfiguriert)
- Production: `noesis2.settings.production`
- Umstellung per Env-Var: `DJANGO_SETTINGS_MODULE=noesis2.settings.production`

## Datenmigration und Standard-Organisation
Beim Upgrade auf die mandantenfÃ¤hige Struktur muss jedem bestehenden Projekt
eine Organisation zugeordnet werden. Die Migration
`projects/migrations/0002_project_organization.py` legt fÃ¼r vorhandene Projekte
automatisch eine Organisation an. Sollten nach dem Deploy noch Projekte ohne
Organisation existieren (z.Â B. nach einem manuellen Datenimport), kann der
Management-Befehl `assign_default_org` genutzt werden:

```bash
python manage.py assign_default_org
```

Der Befehl erzeugt fÃ¼r jedes betroffene Projekt eine neue Organisation und
aktualisiert das Projekt entsprechend.

## Tenant-Verwaltung

Eine ausfÃ¼hrliche Anleitung zur Einrichtung und Pflege von Mandanten (inkl. lokalem Setup, Admin/Operatorâ€‘Rollen und Xâ€‘Tenantâ€‘Schema) befindet sich im Dokument [docs/multi-tenancy.md](docs/multi-tenancy.md).

## Operator-Kommandos (Makefile)

Im Projektwurzelverzeichnis stehen Makefile-Targets zur VerfÃ¼gung, um wiederkehrende Operator-Aufgaben auszufÃ¼hren:

- `make jobs:migrate` â€“ fÃ¼hrt `python manage.py migrate_schemas --noinput` aus.
- `make jobs:bootstrap` â€“ legt den Ã¶ffentlichen Tenant per `bootstrap_public_tenant` an (`DOMAIN` erforderlich).
- `make tenant-new` â€“ erstellt ein neues Schema und die zugehÃ¶rige Domain (`SCHEMA`, `NAME`, `DOMAIN`).
- `make tenant-superuser` â€“ erzeugt einen Superuser in einem Schema (`SCHEMA`, `USERNAME`, `PASSWORD`, optional `EMAIL`).
- `make jobs:rag` â€“ spielt [`docs/rag/schema.sql`](docs/rag/schema.sql) gegen den RAG-Store ein (`RAG_DATABASE_URL` oder fallback `DATABASE_URL`).
- `make jobs:rag:health` â€“ prÃ¼ft Schema, Tabellen und `vector`-Extension im RAG-Store (`RAG_DATABASE_URL` oder fallback `DATABASE_URL`).

Setze die benÃ¶tigten Umgebungsvariablen vor dem Aufruf, z.â€¯B.:

```bash
export DOMAIN=demo.localhost
export SCHEMA=demo
export NAME="Demo GmbH"
export USERNAME=admin
export PASSWORD=changeme
export RAG_DATABASE_URL=postgresql://user:pass@host:5432/rag
```

`RAG_DATABASE_URL` kann leer bleiben, sofern `DATABASE_URL` auf dieselbe Instanz zeigt. FÃ¼r alternative Python-Binaries lÃ¤sst sich `PYTHON` Ã¼berschreiben (`make PYTHON=python3 jobs:migrate`).

## LiteLLM Proxy (lokal)
- `.env.example` â†’ `.env` kopieren und `GOOGLE_API_KEY` setzen
- Start: `docker compose -f docker-compose.yml -f docker-compose.dev.yml up -d litellm`
- Healthcheck: `curl -s http://localhost:4000/health`
- Admin UI Login: StandardmÃ¤ÃŸig via Master Key (Wahl im UI). Alternativ User/Pass Ã¼ber `UI_USERNAME`/`UI_PASSWORD` setzen (in dev/staging per Compose auf `DB_USER`/`DB_PASSWORD` voreingestellt).

## Frontend-Build (Tailwind v4 via PostCSS)
- Build/Watch: `npm run build:css` (wird in `npm run dev` automatisch gestartet)
- Konfiguration: `postcss.config.js` mit `@tailwindcss/postcss` und `autoprefixer`
- Eingabe/Ausgabe: `theme/static_src/input.css` â†’ `theme/static/css/output.css`

## Frontend-Richtlinien
- [Frontend-Ãœberblick](docs/frontend-ueberblick.md)
- Der vollstÃ¤ndige Rahmen fÃ¼r React/TypeScript-Komponenten ist im [Frontend Master Prompt](docs/frontend-master-prompt.md) beschrieben.

## Testing
- Bevorzugt: in Docker ausfÃ¼hren, siehe Abschnitt "Lokales Testen".
- Schnelllauf: `docker compose -f docker-compose.dev.yml run --rm web sh -c "pip install -r requirements.txt -r requirements-dev.txt && python -m pytest -q"`
- Mit Coverage: `docker compose -f docker-compose.dev.yml run --rm web sh -c "pip install -r requirements.txt -r requirements-dev.txt && python -m pytest -q --cov=noesis2 --cov-report=term-missing"`
- Kurzbefehle: `npm run test:py` bzw. `npm run test:py:cov`
- Hinweis: Direktes `pytest` auf dem Host fÃ¼hrt hÃ¤ufig zu DB-/Hostname-Fehlern (kein `db` im Compose-Netz). Nur nativ ausfÃ¼hren, wenn Postgres/Redis lokal verfÃ¼gbar und korrekt konfiguriert sind.

## Linting & Formatierung
- PrÃ¼fen: `npm run lint` (ruff + black --check)
- Fixen: `npm run lint:fix` (ruff --fix + black)

## AbhÃ¤ngigkeitsmanagement (pip-tools)
- Produktion: `pip-compile requirements.in` â†’ `requirements.txt`
- Entwicklung: `pip-compile requirements-dev.in` â†’ `requirements-dev.txt`
- Installation: `pip install -r requirements*.txt`

## Troubleshooting (Windows)
- Nur bei nativer AusfÃ¼hrung ohne Docker relevant: Falls `pytest`, `black`, `ruff` oder `pip-compile` nicht gefunden werden, `%APPDATA%\Python\Python313\Scripts` zum PATH hinzufÃ¼gen.
- `.env` sollte UTFâ€‘8 ohne BOM sein (bei Parsen-Fehlern Datei neu speichern).
