# NOESIS 2

## Vision
KI-gest√ºtzte SaaS-Plattform zur prozessualen Unterst√ºtzung der betrieblichen Mitbestimmung nach ¬ß 87 Abs. 1 Nr. 6 BetrVG.

> üìò **Zentrale Leitplanken & Navigation:** [AGENTS.md](AGENTS.md) b√ºndelt Rollen, Trigger und Links zu allen Prim√§rquellen.
>
> üöÄ **Neu im Projekt?** Der [Onboarding-Leitfaden](docs/development/onboarding.md) f√ºhrt Schritt f√ºr Schritt durch Setup, Skripte und weiterf√ºhrende Dokumentation.

## Kernfunktionen (Geplant)
- Flexible, workflow-basierte Analyse von Dokumenten (z. B. Systembeschreibungen, Betriebsvereinbarungen)
- Mandantenf√§higkeit zur Trennung von Daten verschiedener Parteien (Arbeitgeber, Betriebsr√§te, Anw√§lte)
- Wissensgenerierung und -abfrage durch angebundene Large Language Models (LLMs)
- Asynchrone Verarbeitung von rechenintensiven Analyse-Aufgaben

---

## Technologie-Stack
- Backend: Python 3.12+ mit Django 5.x
- Asynchrone Tasks: Celery & Redis
- Datenbank: PostgreSQL
- Frontend: Tailwind CSS v4 (PostCSS)
- Entwicklungsumgebung: Node.js, npm
- CI/CD & Testing: GitHub Actions, pytest

## AI Core

### API-Endpunkte
Alle Pfade erfordern die Header `X-Tenant-ID`, `X-Case-ID` sowie `Idempotency-Key`. Antworten enthalten Standard-Trace-Header und optionale `gaps` oder `citations`. Der `Idempotency-Key` muss pro Mandant und Vorgang eindeutig sein, damit wiederholte POST-Aufrufe dedupliziert werden k√∂nnen.

- `GET /ai/ping/` ‚Äì einfacher Health-Check
- `POST /ai/intake/` ‚Äì Metadaten speichern und Eingangsbest√§tigung liefern
- `POST /ai/scope/` ‚Äì Auftragsumfang pr√ºfen und fehlende Angaben melden
- `POST /ai/needs/` ‚Äì Informationen dem Tenant-Profil zuordnen, Abbruch bei L√ºcken
- `POST /ai/sysdesc/` ‚Äì Systembeschreibung nur wenn keine Informationen fehlen

### API-Auth
Die Django REST Framework Authentifizierung ist standardm√§√üig deaktiviert, damit √∂ffentliche Mandanten-Endpunkte keinen Bearer-Token erfordern. Admin- oder LiteLLM-Routen binden den Master-Key explizit per View-Decorator. Weil keine SessionAuth aktiv ist, gelten auch keine CSRF-Cookies ‚Äì Token-Clients k√∂nnen ohne CSRF-Header arbeiten.

### Graphen
Die Views orchestrieren reine Python-Graphen. Jeder Graph erh√§lt `state: dict` und `meta: {tenant, case, trace_id}` und gibt `(new_state, result)` zur√ºck. Der Zustand wird nach jedem Schritt in `.ai_core_store/{tenant}/{case}/state.json` persistiert. Gates wie `needs_mapping` oder `scope_check` brechen fr√ºh ab, statt unvollst√§ndige Drafts zu erzeugen.

### Lokale Nutzung
Das bestehende `docker compose`-Setup startet Web-App und Redis. Ein externer LiteLLM-Proxy kann √ºber `LITELLM_BASE_URL` angebunden werden. Nach dem Start (`docker compose ... up`) k√∂nnen die Endpunkte lokal unter `http://localhost:8000/ai/` getestet werden.

### PII-Scope Playbook
Der Session-Scope sorgt daf√ºr, dass dieselben deterministischen Platzhalter in Requests, LLM-Aufrufen, Logs und Tasks genutzt werden. Das Playbook [docs/pii-scope.md](docs/pii-scope.md) beschreibt die Reihenfolge (Middleware ‚Üí Masking ‚Üí Logging ‚Üí Tasks ‚Üí Egress), enth√§lt eine Review-Checkliste und eine FastAPI-Referenz f√ºr Microservices.

---

## Entwicklungsworkflow mit Docker

### 1Ô∏è‚É£ Vorbereitung
- `.env.example` nach `.env` kopieren (Windows: `copy`, Linux/macOS: `cp`).
- Optional: vorhandene Secrets und API-Keys erg√§nzen (LiteLLM, Gemini, Langfuse ‚Ä¶).
- F√ºr den ELK-Stack die Defaults aus `.env.dev-elk` √ºbernehmen (z.‚ÄØB. `cat .env.dev-elk >> .env`), damit Passw√∂rter f√ºr `elastic` und `kibana_system` gesetzt sind.

### 2Ô∏è‚É£ Build & Start
```bash
docker compose -f docker-compose.yml -f docker-compose.dev.yml build
docker compose -f docker-compose.yml -f docker-compose.dev.yml up -d
```

> üí° **Alles in einem Schritt?** `npm run dev:stack` baut App- und ELK-Images, startet beide Compose-Stacks, f√ºhrt Migrationen/Bootstrap aus und seedet Demo- sowie Heavy-Datens√§tze.

### 3Ô∏è‚É£ Bootstrap & Smoke-Checks
```bash
npm run dev:up
npm run dev:check
```

Die Skripte sind idempotent: Sie legen fehlende Tenants/Superuser an, f√ºhren `migrate_schemas` aus und pr√ºfen LiteLLM sowie die AI-Endpunkte (`/ai/ping`, `/ai/scope`).

> ‚ÑπÔ∏è **Compose-Notizen**
> - Der `web`-Container f√ºhrt `collectstatic` automatisch aus (Storage: `CompressedManifestStaticFilesStorage`).
> - Volumes bleiben bei `up -d` erhalten. F√ºr einen vollst√§ndigen Reset siehe `npm run dev:reset`.
> - Container lesen `.env.docker`. Host-Tools nutzen weiterhin `.env`.

### H√§ufige Docker-Kommandos

| Kommando | Zweck |
| --- | --- |
| `docker compose -f docker-compose.yml -f docker-compose.dev.yml up` | Start im Vordergrund (Logs im Terminal) |
| `docker compose -f docker-compose.yml -f docker-compose.dev.yml up -d` | Start im Hintergrund |
| `docker compose -f docker-compose.yml -f docker-compose.dev.yml down` | Stoppen ohne Volumes zu l√∂schen |
| `docker compose -f docker-compose.yml -f docker-compose.dev.yml down -v` | Stoppen inkl. Entfernen der Volumes |
| `docker compose -f docker-compose.yml -f docker-compose.dev.yml ps` | Status√ºbersicht der laufenden Container |

### Quality-of-Life Skripte (npm)

| Script | Beschreibung |
| --- | --- |
| `npm run dev:up` | Initialisiert Datenbank & Tenants im Compose-Stack, erstellt Superuser |
| `npm run dev:check` | F√ºhrt Health-Checks (LiteLLM, `/ai/ping`, `/ai/scope`) aus |
| `npm run dev:init` | F√ºhrt `jobs:migrate` und `jobs:bootstrap` aus (nach `up -d`) |
| `npm run dev:stack` | Startet App + ELK, Migrationen, Bootstrap, Demo- & Heavy-Seeding |
| `npm run dev:down` | Stoppt alle Container inkl. Volumes (`down -v`) |
| `npm run dev:restart` | Neustart von Web- und Worker-Containern |
| `npm run dev:rebuild` | Rebuild von Web-/Worker-Images (`-- --with-frontend` f√ºr Tailwind) |
| `npm run dev:reset` | Komplettreset (down -v ‚Üí build --no-cache ‚Üí up -d ‚Üí init ‚Üí check) |
| `npm run dev:manage <cmd>` | F√ºhrt `python manage.py <cmd>` im `web`-Container aus |
| `npm run jobs:migrate` | Compose-Job `migrate` f√ºr `migrate_schemas` |
| `npm run jobs:bootstrap` | Compose-Job `bootstrap_public_tenant` |
| `npm run jobs:rag` | F√ºhrt `docs/rag/schema.sql` gegen das RAG-Schema aus |
| `npm run jobs:rag:health` | Pr√ºft pgvector/RAG-Schema |

Windows-Varianten (PowerShell) stehen als `npm run win:<script>` zur Verf√ºgung (z.‚ÄØB. `win:dev:up`, `win:dev:rebuild`).

### API-Schema & SDKs

| Kommando | Ergebnis |
| --- | --- |
| `npm run api:schema` | Exportiert das OpenAPI-Schema in `docs/api/openapi.yaml` (lokal, ohne Docker-Compose) |
| `make schema` | Baut `docs/api/openapi.yaml` via `manage.py spectacular` |
| `make sdk` | Generiert TypeScript- (`clients/typescript`) und Python-SDKs (`clients/python`) auf Basis des aktuellen Schemas |

`make sdk` ruft `make schema` implizit auf. F√ºr die SDK-Generierung m√ºssen Node.js (f√ºr `openapi-typescript-codegen`) und die Python-CLI `openapi-python-client` verf√ºgbar sein ‚Äì beide sind in den Projektabh√§ngigkeiten enthalten.

### Frontend & Tooling

| Script | Beschreibung |
| --- | --- |
| `npm run dev` | Lokaler Django-Server + Tailwind-Watcher (nur ohne Docker sinnvoll) |
| `npm run build:css` | Einmaliger Tailwind-Build |
| `npm run build:css:watch` | Tailwind-Watcher |
| `npm run storybook` | Startet Storybook (Port 6006) |
| `npm run storybook:build` | Erzeugt statischen Storybook-Build |
| `npm run e2e` | Playwright E2E-Tests |
| `npm run test` | Vitest-Unit-Tests f√ºr Frontend |
| `npm run test:py` | Python-Tests innerhalb des Web-Containers |
| `npm run test:py:cov` | Python-Tests inkl. Coverage |
| `npm run lint` | Ruff + Black (Check-Modus) |
| `npm run lint:fix` | Ruff (Fix) + Black Formatierung |
| `npm run format` | Prettier f√ºr JS/TS/CSS/MD/JSON |
| `npm run hooks:install` | Git-Hooks (pre-push) f√ºr macOS/Linux |
| `npm run win:hooks:install` | Git-Hooks Installation f√ºr Windows |

### Make Targets

| Target | Beschreibung |
| --- | --- |
| `make jobs:migrate` | F√ºhrt `migrate_schemas --noinput` aus |
| `make jobs:bootstrap` | Erstellt den Public-Tenant (`DOMAIN` erforderlich) |
| `make tenant-new` | Legt einen neuen Tenant an (`SCHEMA`, `NAME`, `DOMAIN`) |
| `make tenant-superuser` | Erstellt einen Tenant-Superuser (`SCHEMA`, `USERNAME`, `PASSWORD`, optional `EMAIL`) |
| `make jobs:rag` | Spielt `docs/rag/schema.sql` gegen `RAG_DATABASE_URL`/`DATABASE_URL` ein |
| `make jobs:rag:health` | Validiert RAG-Schema & `vector`-Extension |
| `make schema` | Exportiert das OpenAPI-Schema nach `docs/api/openapi.yaml` |
| `make sdk` | Generiert SDKs unter `clients/` auf Basis des aktuellen Schemas |

Alle Make-Targets greifen auf lokale Tools (`psql`, `python`). Innerhalb des Compose-Stacks empfiehlt sich die Nutzung der √§quivalenten npm-Skripte (`npm run jobs:*`).

## Tests & Qualit√§tssicherung

```bash
npm run test:py        # Django/Celery Tests im Container
npm run test           # Frontend Tests (Vitest)
npm run lint           # Ruff + Black Checks
npm run e2e            # Playwright E2E
```

Der Python-Test-Runner installiert die ben√∂tigten Abh√§ngigkeiten on-the-fly in einem tempor√§ren Container und r√§umt nach dem Lauf automatisch auf.

### Chaos-Tests (Fault Injection)

- `pytest -m chaos` f√ºhrt nur die gezielt markierten Fault-Injection-Szenarien aus. Die Tests nutzen den Fixture `chaos_env`, um die Runtime-Schalter `REDIS_DOWN`, `SQL_DOWN` und `SLOW_NET` konsistent zu setzen.
- In GitHub Actions existiert der optionale Stage-Job `tests-chaos`, der √ºber einen manuellen Workflow-Dispatch mit `run_chaos=true` gestartet wird. Der Job l√§uft parallelisiert via `pytest -m chaos -q -n auto`, erzeugt JUnit- und JSON-Artefakte sowie optionale k6-/Locust-Summaries und ist nach erfolgreichem Staging-Smoke-Test (Pipeline Stufen¬†8‚Äì10) als zus√§tzlicher QA-Gate vorgesehen. Weitere Details siehe [Pipeline-Dokumentation](docs/cicd/pipeline.md).
  - F√ºr das Eingabefeld `run_chaos` akzeptiert der Workflow sowohl Boolean- als auch String-Werte. Die interne Normalisierung ergibt `RUN_CHAOS=true` ausschlie√ülich f√ºr folgende Eingaben:
    - `true` (Boolean in der UI, Standard bei H√§kchen)
    - `"true"` (String via `gh workflow run` oder API)
  - Jede andere Eingabe (`false`, `"false"`, leer, nicht gesetzt) f√ºhrt zu `RUN_CHAOS=false`. Dieser Mini-Wahrheitstisch hilft, versehentliche Chaos-Runs bei benutzerdefinierten Dispatches oder Automatisierungen zu vermeiden.
- Freigaben erfolgen nur, wenn die zugeh√∂rigen [QA-Checklisten](docs/qa/checklists.md) als Gate dokumentiert und abgehakt sind.

#### Netzwerkchaos via Toxiproxy

- `docker compose up -d toxiproxy` startet den Proxy-Container lokal und richtet feste Listener ein (`localhost:15432` ‚Üí PostgreSQL, `localhost:16379` ‚Üí Redis, Admin-API unter `localhost:8474`). Die Web-/Worker-Container sprechen standardm√§√üig weiterhin `db`/`redis` an; zum Testen √ºber den Proxy setze `COMPOSE_DATABASE_URL=postgresql://noesis2:noesis2@toxiproxy:15432/noesis2` bzw. `COMPOSE_REDIS_URL=redis://toxiproxy:16379/0`.
- Das Skript `scripts/chaos/toxiproxy.sh` verwaltet die ben√∂tigten Toxics. Mit `SLOW_NET=true scripts/chaos/toxiproxy.sh enable` werden Latenz, Bandbreitenlimit und Reset-Peers √ºber die CLI injiziert; `scripts/chaos/toxiproxy.sh disable` r√§umt alles wieder auf. `status` zeigt den aktuellen Proxy-Zustand.
- Jeder Start/Stop wird samt Parametern in `logs/chaos/toxiproxy.log` protokolliert. Das File dient als Marker im ELK-Stack (Filebeat-Pickup oder manuelles Hochladen), damit sich Chaosphasen eindeutig mit Applikationslogs und Langfuse-Traces korrelieren lassen.

#### Chaos-Reporting & ELK-Verzahnung

- Chaos-Tests erzeugen pro Testlauf strukturierte Artefakte unter `logs/app/chaos/*.json`. Die Dateien enthalten u.‚ÄØa. `test_suite: "chaos"`, das `nodeid`, den Ausgang sowie die aktivierten Schalter aus `chaos_env`.
- Der lokale ELK-Stack liest die JSON-Artefakte automatisch ein. Starte ihn bei Bedarf mit `docker compose -f docker/elk/docker-compose.yml up -d` und stoppe ihn anschlie√üend wieder mit `docker compose -f docker/elk/docker-compose.yml down`.
- In Kibana gen√ºgt eine Discover-Abfrage `test_suite:chaos`, um ausschlie√ülich Chaos-Reports zu filtern und die Laufzeiten/Fehler direkt mit Applikationslogs zu korrelieren. Weitere Details siehe [docs/observability/elk.md](docs/observability/elk.md).

### Load-Testing Setup (k6 & Locust)

- **Skripte:**
  - `npm run load:k6` bzw. `make load:k6` startet das Spike+Soak-Szenario aus `load/k6/script.js`. Setze daf√ºr die Staging-Parameter (`STAGING_WEB_URL`, `STAGING_TENANT_SCHEMA`, `STAGING_TENANT_ID`, `STAGING_CASE_ID`, optional `STAGING_BEARER_TOKEN`, `STAGING_KEY_ALIAS`). Zus√§tzliche Parameter wie `SCOPE_SOAK_DURATION` k√∂nnen via ENV angepasst werden.
  - `npm run load:locust` bzw. `make load:locust` l√§dt die User-Klassen aus `load/locust/locustfile.py`. √úbergib weitere Flags nach `--`, z.‚ÄØB. `npm run load:locust -- --headless -u 30 -r 10 --run-time 5m`.
- **Matrix & Scaling:** F√ºr Staging orientiert sich die Grundlast an der Web-Concurrency (~30 Worker). Nutze f√ºr Locust `-u 30` (gleichzeitige Nutzer) als Basis und erh√∂he schrittweise (z.‚ÄØB. 30 ‚Üí 60 ‚Üí 90) je nach QA-Plan. F√ºr k6 beschreibt das Script ein kurzes Spike+Soak-Profil mit Ramp-Up/-Down und optionalen Overrides (`SCOPE_SPIKE_RPS`, `SCOPE_SOAK_RPS`).
- **Tenancy & Idempotency:** Beide Skripte injizieren die Header `X-Tenant-Schema`, `X-Tenant-ID`, `X-Case-ID` sowie eindeutige `Idempotency-Key`s. Standardpayloads folgen den Beispielen aus [docs/api/reference.md](docs/api/reference.md) und lassen sich √ºber ENV-Overrides (`LOCUST_SCOPE_PAYLOAD`, `LOCUST_INGESTION_PAYLOAD`, ‚Ä¶) anpassen.
- **Ausf√ºhrung:** Die Load-Skripte sind nicht in CI eingebunden. F√ºhre sie manuell lokal oder gegen Staging aus (siehe [docs/cloud/gcp-staging.md](docs/cloud/gcp-staging.md) f√ºr URLs und Credentials) und archiviere Metriken/Artefakte als Bestandteil der QA-Gates.

## Manuelles Setup ohne Docker

F√ºr Systeme ohne Docker-Unterst√ºtzung gibt es einen dokumentierten Fallback:
[docs/development/manual-setup.md](docs/development/manual-setup.md).

## Konfiguration (.env)
Ben√∂tigte Variablen (siehe `.env.example` oder `.env.dev.sample`):

- SECRET_KEY: geheimer Schl√ºssel f√ºr Django
- DEBUG: `true`/`false`
- DB_USER / DB_PASSWORD / DB_NAME: gemeinsame Dev‚ÄëCredentials; werden f√ºr den Container‚ÄëInit und DSNs genutzt.
- DATABASE_URL: Verbindungs-URL zur PostgreSQL-Datenbank (App‚ÄëDB, default: `postgresql://noesis2:noesis2@db:5432/noesis2`)
- REDIS_URL: Redis-Endpoint (z. B. f√ºr Celery)
- RAG_DATABASE_URL (optional): separates DSN f√ºr das pgvector-Schema. Ohne Angabe nutzt der Stack `DATABASE_URL`.
  Stelle sicher, dass [`docs/rag/schema.sql`](docs/rag/schema.sql) angewendet wurde und die `vector`-Extension aktiv ist.
  Mandanten-IDs m√ºssen UUIDs sein; vorhandene Legacy-IDs werden deterministisch gemappt, sollten aber per Migration bereinigt
  werden, bevor produktive Daten geladen werden.

AI Core:
- LITELLM_BASE_URL: Basis-URL des LiteLLM-Proxys
- LITELLM_API_KEY: API-Key f√ºr den Proxy
- LITELLM_DATABASE_URL (optional): separates DB‚ÄëDSN f√ºr die LiteLLM Admin‚ÄëDB (default in Compose aus `DB_*` + `LITELLM_DB_NAME`)
- LANGFUSE_PUBLIC_KEY / LANGFUSE_SECRET_KEY: Schl√ºssel f√ºr Langfuse-Tracing
- LITELLM_SALT_KEY: Salt f√ºr Verschl√ºsselung gespeicherter Provider‚ÄëKeys in der Admin‚ÄëDB (empfohlen f√ºr Admin UI)

Die Settings lesen `.env` via `django-environ`. `DATABASE_URL` muss eine vollst√§ndige URL enthalten (inkl. URL-Encoding f√ºr Sonderzeichen); `REDIS_URL` wird sowohl f√ºr Celery als auch f√ºr Redis-basierte Integrationen verwendet.

Best Practice: In Dev einen gemeinsamen DB‚ÄëUser f√ºr App und LiteLLM verwenden (einfachere Einrichtung). In Produktion getrennte Rollen/DSNs je Dienst (Least Privilege).

## LiteLLM & Modelle (Prod vs. Lokal)
- Produktion (Cloud Run)
  - LiteLLM authentifiziert gegen Vertex AI per Service Account (ADC), kein API‚ÄëKey n√∂tig.
  - Regionensplit: Cloud Run `europe-west3`, Vertex `us-central1` (siehe `scripts/init_litellm_gcloud.sh` und CI).
  - Routing: `MODEL_ROUTING.yaml` zeigt auf `vertex_ai/*` Modelle (z. B. `vertex_ai/gemini-2.5-flash`).
  - Labels ‚Üí Modelle (Vertex AI):
    - `default`, `fast`, `simple-query`, `synthesize`, `extract`, `classify`, `analyze` ‚Üí `vertex_ai/gemini-2.5-flash`
    - `reasoning`, `draft` ‚Üí `vertex_ai/gemini-2.5-pro`
    - `embedding` ‚Üí `vertex_ai/text-embedding-004`
  - CI setzt `VERTEXAI_PROJECT` und `VERTEXAI_LOCATION` und pinned die Cloud‚ÄëRun Service‚ÄëAccount‚ÄëIdentit√§t.

- Lokal (Docker Compose)
  - Vertex ADC steht lokal i. d. R. nicht zur Verf√ºgung. Nutze AI‚ÄëStudio (Gemini) √ºber LiteLLM‚ÄëConfig.
  - Datei `config/litellm-config.yaml` ist f√ºr AI‚ÄëStudio konfiguriert (`gemini/*` + `GEMINI_API_KEY`).
  - Erzeuge eine lokale Routing‚ÄëOverride, damit Django lokale Modelle anspricht:
    ```bash
    cp MODEL_ROUTING.local.yaml.sample MODEL_ROUTING.local.yaml
    ```
  - Setze in `.env` mindestens:
    - `GEMINI_API_KEY=<dein_ai_studio_key>`
    - `LITELLM_MASTER_KEY=<beliebiger_dev_key>`
  - Starte LiteLLM via Compose und teste:
    ```bash
    docker compose -f docker-compose.yml -f docker-compose.dev.yml up -d litellm
    bash scripts/smoke_litellm.sh
    ```

  - Labels ‚Üí Modelle (AI Studio):
    - `default`, `fast`, `simple-query`, `synthesize`, `extract`, `classify`, `analyze` ‚Üí `gemini-2.5-flash`
    - `reasoning`, `draft` ‚Üí `gemini-2.5-pro`
    - `embedding` ‚Üí `google/text-embedding-004`

Hinweis: `MODEL_ROUTING.local.yaml` ist git‚Äëignored und √ºberschreibt nur lokal. In Prod wird ausschlie√ülich `MODEL_ROUTING.yaml` verwendet.

## Observability

- [Langfuse Guide](docs/observability/langfuse.md)
- [ELK Stack f√ºr lokale Entwicklung](docs/observability/elk.md) ‚Äî Oneshot-Bootstrap: `bash scripts/dev-up-all.sh`

## GCloud Bootstrap (Windows)
Mit dem Skript `scripts/gcloud-bootstrap.ps1` kannst du dich per `gcloud` anmelden, ein Projekt/Region w√§hlen und h√§ufige Laufzeitwerte aus GCP sammeln (Redis, Cloud SQL, Cloud Run URLs). Die Werte werden sicher in `.env.gcloud` geschrieben (Git-ignored) und k√∂nnen selektiv in deine `.env` √ºbernommen werden.

PowerShell (Windows):

```powershell
pwsh -File scripts/gcloud-bootstrap.ps1
# oder nicht-interaktiv mit Vorgaben:
pwsh -File scripts/gcloud-bootstrap.ps1 -Region europe-west3 -Zone europe-west3-a

# Optional: Secrets explizit ziehen (schreibt sensible Werte in .env.gcloud!)
pwsh -File scripts/gcloud-bootstrap.ps1 -FetchSecrets -Secrets SECRET_KEY,LANGFUSE_KEY
```

Hinweise:
- Secrets werden standardm√§√üig nicht geladen. Mit `-FetchSecrets` + `-Secrets` kannst du gezielt Secret-Names laden, sofern dein Account berechtigt ist.
- F√ºr Cloud SQL im lokalen Setup bevorzugen wir weiterhin die lokale DB (Docker). Alternativ Cloud SQL Auth Proxy verwenden und `DB_HOST`/`DATABASE_URL` passend setzen.

## GCloud Bootstrap (Bash/WSL/Linux)
Das Bash-Pendant l√§uft unter WSL oder Linux. Es sammelt dieselben Werte und schreibt `.env.gcloud` (Git-ignored).

```bash
# Interaktiv
bash scripts/gcloud-bootstrap.sh

# Mit Parametern
bash scripts/gcloud-bootstrap.sh --region europe-west3 --zone europe-west3-a

# Optional Secrets (vorsichtig)
bash scripts/gcloud-bootstrap.sh --fetch-secrets \
  --secret SECRET_KEY --secret LANGFUSE_KEY
```

Voraussetzungen: `gcloud` im PATH. `jq` ist nicht erforderlich.

## Settings-Profile
Das alte `noesis2/settings.py` wurde entfernt; verwende ausschlie√ülich das modulare Paket `noesis2/settings/`.

- Standard: `noesis2.settings.development` (in `manage.py`, `asgi.py`, `wsgi.py` vorkonfiguriert)
- Production: `noesis2.settings.production`
- Umstellung per Env-Var: `DJANGO_SETTINGS_MODULE=noesis2.settings.production`

## Datenmigration und Standard-Organisation
Beim Upgrade auf die mandantenf√§hige Struktur muss jedem bestehenden Projekt
eine Organisation zugeordnet werden. Die Migration
`projects/migrations/0002_project_organization.py` legt f√ºr vorhandene Projekte
automatisch eine Organisation an. Sollten nach dem Deploy noch Projekte ohne
Organisation existieren (z.¬†B. nach einem manuellen Datenimport), kann der
Management-Befehl `assign_default_org` genutzt werden:

```bash
python manage.py assign_default_org
```

Der Befehl erzeugt f√ºr jedes betroffene Projekt eine neue Organisation und
aktualisiert das Projekt entsprechend.

## Tenant-Verwaltung

Eine ausf√ºhrliche Anleitung zur Einrichtung und Pflege von Mandanten (inkl. lokalem Setup, Admin/Operator‚ÄëRollen und X‚ÄëTenant‚ÄëSchema) befindet sich im Dokument [docs/multi-tenancy.md](docs/multi-tenancy.md).

## Operator-Kommandos (Makefile)

Im Projektwurzelverzeichnis stehen Makefile-Targets zur Verf√ºgung, um wiederkehrende Operator-Aufgaben auszuf√ºhren:

- `make jobs:migrate` ‚Äì f√ºhrt `python manage.py migrate_schemas --noinput` aus.
- `make jobs:bootstrap` ‚Äì legt den √∂ffentlichen Tenant per `bootstrap_public_tenant` an (`DOMAIN` erforderlich).
- `make tenant-new` ‚Äì erstellt ein neues Schema und die zugeh√∂rige Domain (`SCHEMA`, `NAME`, `DOMAIN`).
- `make tenant-superuser` ‚Äì erzeugt einen Superuser in einem Schema (`SCHEMA`, `USERNAME`, `PASSWORD`, optional `EMAIL`).
- `make jobs:rag` ‚Äì spielt [`docs/rag/schema.sql`](docs/rag/schema.sql) gegen den RAG-Store ein (`RAG_DATABASE_URL` oder fallback `DATABASE_URL`).
- `make jobs:rag:health` ‚Äì pr√ºft Schema, Tabellen und `vector`-Extension im RAG-Store (`RAG_DATABASE_URL` oder fallback `DATABASE_URL`).

Setze die ben√∂tigten Umgebungsvariablen vor dem Aufruf, z.‚ÄØB.:

```bash
export DOMAIN=demo.localhost
export SCHEMA=demo
export NAME="Demo GmbH"
export USERNAME=admin
export PASSWORD=changeme
export RAG_DATABASE_URL=postgresql://user:pass@host:5432/rag
```

`RAG_DATABASE_URL` kann leer bleiben, sofern `DATABASE_URL` auf dieselbe Instanz zeigt. F√ºr alternative Python-Binaries l√§sst sich `PYTHON` √ºberschreiben (`make PYTHON=python3 jobs:migrate`).

## LiteLLM Proxy (lokal)
- `.env.example` ‚Üí `.env` kopieren und `GOOGLE_API_KEY` setzen
- Start: `docker compose -f docker-compose.yml -f docker-compose.dev.yml up -d litellm`
- Healthcheck: `curl -s http://localhost:4000/health`
- Admin UI Login: Standardm√§√üig via Master Key (Wahl im UI). Alternativ User/Pass √ºber `UI_USERNAME`/`UI_PASSWORD` setzen (in dev/staging per Compose auf `DB_USER`/`DB_PASSWORD` voreingestellt).

## Frontend-Build (Tailwind v4 via PostCSS)
- Build/Watch: `npm run build:css` (wird in `npm run dev` automatisch gestartet)
- Konfiguration: `postcss.config.js` mit `@tailwindcss/postcss` und `autoprefixer`
- Eingabe/Ausgabe: `theme/static_src/input.css` ‚Üí `theme/static/css/output.css`

## Frontend-Richtlinien
- [Frontend-√úberblick](docs/frontend-ueberblick.md)
- Der vollst√§ndige Rahmen f√ºr React/TypeScript-Komponenten ist im [Frontend Master Prompt](docs/frontend-master-prompt.md) beschrieben.

## Testing
- Bevorzugt: in Docker ausf√ºhren, siehe Abschnitt "Lokales Testen".
- Schnelllauf: `docker compose -f docker-compose.dev.yml run --rm web sh -c "pip install -r requirements.txt -r requirements-dev.txt && python -m pytest -q"`
- Mit Coverage: `docker compose -f docker-compose.dev.yml run --rm web sh -c "pip install -r requirements.txt -r requirements-dev.txt && python -m pytest -q --cov=noesis2 --cov-report=term-missing"`
- Kurzbefehle: `npm run test:py` bzw. `npm run test:py:cov`
- Hinweis: Direktes `pytest` auf dem Host f√ºhrt h√§ufig zu DB-/Hostname-Fehlern (kein `db` im Compose-Netz). Nur nativ ausf√ºhren, wenn Postgres/Redis lokal verf√ºgbar und korrekt konfiguriert sind.

## Linting & Formatierung
- Pr√ºfen: `npm run lint` (ruff + black --check)
- Fixen: `npm run lint:fix` (ruff --fix + black)

## Abh√§ngigkeitsmanagement (pip-tools)
- Produktion: `pip-compile requirements.in` ‚Üí `requirements.txt`
- Entwicklung: `pip-compile requirements-dev.in` ‚Üí `requirements-dev.txt`
- Installation: `pip install -r requirements*.txt`

## Troubleshooting (Windows)
- Nur bei nativer Ausf√ºhrung ohne Docker relevant: Falls `pytest`, `black`, `ruff` oder `pip-compile` nicht gefunden werden, `%APPDATA%\Python\Python313\Scripts` zum PATH hinzuf√ºgen.
- `.env` sollte UTF‚Äë8 ohne BOM sein (bei Parsen-Fehlern Datei neu speichern).
