# NOESIS 2

## Vision
KI-gest√ºtzte SaaS-Plattform zur prozessualen Unterst√ºtzung der betrieblichen Mitbestimmung nach ¬ß 87 Abs. 1 Nr. 6 BetrVG.

> üìò **Zentrale Leitplanken & Navigation:** [AGENTS.md](AGENTS.md) b√ºndelt Rollen, Trigger und Links zu allen Prim√§rquellen.
>
> üöÄ **Neu im Projekt?** Der [Onboarding-Leitfaden](docs/development/onboarding.md) f√ºhrt Schritt f√ºr Schritt durch Setup, Skripte und weiterf√ºhrende Dokumentation.

## Kernfunktionen (Geplant)
- Flexible, workflow-basierte Analyse von Dokumenten (z. B. Systembeschreibungen, Betriebsvereinbarungen)
- Mandantenf√§higkeit zur Trennung von Daten verschiedener Parteien (Arbeitgeber, Betriebsr√§te, Anw√§lte)
- Wissensgenerierung und -abfrage durch angebundene Large Language Models (LLMs)
- Asynchrone Verarbeitung von rechenintensiven Analyse-Aufgaben

---

## Technologie-Stack
- Backend: Python 3.12+ mit Django 5.x
- Asynchrone Tasks: Celery & Redis
- Datenbank: PostgreSQL
- Frontend: Tailwind CSS v4 (PostCSS)
- Entwicklungsumgebung: Node.js, npm
- CI/CD & Testing: GitHub Actions, pytest

## AI Core

### API-Endpunkte
Alle Pfade erfordern die Header `X-Tenant-ID`, `X-Case-ID` sowie `Idempotency-Key`. Antworten enthalten Standard-Trace-Header und optionale `gaps` oder `citations`. Der `Idempotency-Key` muss pro Mandant und Vorgang eindeutig sein, damit wiederholte POST-Aufrufe dedupliziert werden k√∂nnen.

- `GET /ai/ping/` ‚Äì einfacher Health-Check
- `POST /ai/intake/` ‚Äì Metadaten speichern und Eingangsbest√§tigung liefern
- `POST /ai/scope/` ‚Äì Auftragsumfang pr√ºfen und fehlende Angaben melden
- `POST /ai/needs/` ‚Äì Informationen dem Tenant-Profil zuordnen, Abbruch bei L√ºcken
- `POST /ai/sysdesc/` ‚Äì Systembeschreibung nur wenn keine Informationen fehlen

### Graphen
Die Views orchestrieren reine Python-Graphen. Jeder Graph erh√§lt `state: dict` und `meta: {tenant, case, trace_id}` und gibt `(new_state, result)` zur√ºck. Der Zustand wird nach jedem Schritt in `.ai_core_store/{tenant}/{case}/state.json` persistiert. Gates wie `needs_mapping` oder `scope_check` brechen fr√ºh ab, statt unvollst√§ndige Drafts zu erzeugen.

### Lokale Nutzung
Das bestehende `docker compose`-Setup startet Web-App und Redis. Ein externer LiteLLM-Proxy kann √ºber `LITELLM_BASE_URL` angebunden werden. Nach dem Start (`docker compose ... up`) k√∂nnen die Endpunkte lokal unter `http://localhost:8000/ai/` getestet werden.

---

## Docker Quickstart
```bash
# Falls noch keine .env vorhanden ist:
# Windows: copy .env.example .env   |   Linux/macOS: cp .env.example .env

docker compose -f docker-compose.yml -f docker-compose.dev.yml build
docker compose -f docker-compose.yml -f docker-compose.dev.yml up -d

# Bootstrap & Checks (idempotent):
npm run dev:up
npm run dev:check
```

Hinweise:
- Wenn bereits eine lokale `.env` mit g√ºltigen Schl√ºsseln existiert, Kopierschritt √ºberspringen.
- Der Entwicklungscontainer f√ºhrt `python manage.py collectstatic` beim Start automatisch aus.
- Bei √§lteren Compose-Setups ggf. manuell:
  `docker-compose exec web python manage.py collectstatic` (notwendig wegen `CompressedManifestStaticFilesStorage`).

---

## Lokales Setup (Alternative ohne Docker)

Docker Compose ist die bevorzugte Methode f√ºr ein konsistentes, schnelles Setup.
Die folgenden Schritte sind ein manueller Fallback, falls Docker nicht genutzt wird.

### Voraussetzungen
- Python 3.12+
- Node.js und npm
- PostgreSQL-Server
- Redis-Server

### Installations-Schritte
1. Repository klonen
   ```bash
   git clone https://github.com/fraven01/NOESIS-2.git
   cd NOESIS-2
   ```
2. Python-Umgebung einrichten
   ```bash
   python -m venv .venv
   # Linux/macOS
   source .venv/bin/activate
   # Windows PowerShell
   .\.venv\Scripts\Activate.ps1

   pip install -r requirements.txt
   pip install -r requirements-dev.txt
   ```
3. Frontend-Abh√§ngigkeiten installieren
   ```bash
   npm install
   ```
4. Datenbank einrichten
   - Leere PostgreSQL-Datenbank erstellen (z. B. `CREATE DATABASE noesis2_db;`).
   - `.env.example` nach `.env` kopieren und Zugangsdaten anpassen.
   - Migrationen ausf√ºhren:
     ```bash
     python manage.py migrate
     ```
5. Superuser anlegen
   ```bash
   python manage.py createsuperuser
   ```

### Entwicklungsserver starten
```bash
npm run dev
```


## Lokales Testen

Die Tests greifen auf die in `docker-compose.dev.yml` definierten Service-Hosts (u. a. `db`) zu. Ausserhalb der Compose-Umgebung fehlen diese Namensaufloesungen und Django bricht mit Verbindungsfehlern ab. Zudem enthaelt das `web`-Image nur Produktionsabhaengigkeiten, daher muessen vor dem Testlauf sowohl Basis- als auch Dev-Abhaengigkeiten installiert werden.

```bash
docker compose -f docker-compose.dev.yml run --rm web sh -c "pip install -r requirements.txt -r requirements-dev.txt && python -m pytest"
```

Der Befehl laedt die benoetigten Pakete in den temporaeren Container, fuehrt die Tests aus und entfernt den Container anschliessend wieder. Fuehre ihn bei jedem frischen Containerlauf erneut aus, da Installationen nicht persistent sind.

## Anwendung ausf√ºhren mit Docker

- `docker compose -f docker-compose.yml -f docker-compose.dev.yml up`: Startet die gesamte Anwendung im Vordergrund (Logs im Terminal).
- `docker compose -f docker-compose.yml -f docker-compose.dev.yml up -d`: Startet die Anwendung im Hintergrund (detached mode).
- `docker compose -f docker-compose.yml -f docker-compose.dev.yml down`: Stoppt und entfernt die Container (Volumes wie Datenbankdaten bleiben erhalten).
- `docker compose -f docker-compose.yml -f docker-compose.dev.yml exec web python manage.py <befehl>`: F√ºhrt einen `manage.py`-Befehl (z. B. `createsuperuser`) im laufenden `web`-Container aus.
- Der Entwicklungscontainer f√ºhrt `python manage.py collectstatic` beim Start automatisch aus.
  Bei √§lteren Compose-Setups muss dieser Schritt manuell erfolgen:
  `docker-compose exec web python manage.py collectstatic`.
  Notwendig, da `CompressedManifestStaticFilesStorage` aktiv ist.
- Datenbankmigrationen laufen nicht automatisch mit. F√ºhre sie bei Bedarf manuell aus, z.‚ÄØB. mit
  `docker compose -f docker-compose.yml -f docker-compose.dev.yml exec web python manage.py migrate`.

### Dev-Skripte (idempotent)
- `npm run dev:up`: Startet/initialisiert die Umgebung, f√ºhrt `migrate_schemas`, bootstrapped den Public‚ÄëTenant, legt `dev`‚ÄëTenant und Superuser an.
- `npm run dev:check`: F√ºhrt Smoke‚ÄëChecks aus (LiteLLM Health/Chat, `GET /ai/ping/`, `POST /ai/scope/`). Chat erfordert g√ºltige `GEMINI_API_KEY`.
- `npm run dev:down`: Stoppt und entfernt alle Container inkl. Volumes.
- `npm run dev:rebuild`: Baut Web- und Worker-Images neu und aktualisiert Code-Abh√§ngigkeiten, ohne Volumes zu l√∂schen. Mit `npm run dev:rebuild -- --with-frontend` l√§sst sich optional auch das Frontend-Image aktualisieren.
- `npm run dev:restart`: Startet Web- und Worker-Container schnell neu (Compose `restart`).
- `npm run dev:init`: F√ºhrt die Compose‚ÄëJobs `migrate` und `bootstrap` aus (nach `up -d`).
- `npm run dev:reset`: Full reset (down -v ‚Üí build --no-cache ‚Üí up -d ‚Üí init ‚Üí checks).
- `npm run jobs:rag`: F√ºhrt `docs/rag/schema.sql` gegen die DB aus (idempotent).
- `npm run rag:enable`: Setzt `RAG_ENABLED=true` in `.env` und startet Web/Worker neu.
 - `npm run jobs:rag:health`: Pr√ºft RAG-Gesundheit (pgvector installiert, Tabellen vorhanden).

**Wann welches Skript?**
- Konfigurationswerte, Feature-Flags oder Django-Code ge√§ndert und die laufenden Container sollen die √Ñnderungen aufnehmen ‚Üí `npm run dev:restart` (Windows: `npm run win:dev:restart`).
- Neue Python-/Node-Abh√§ngigkeiten installiert oder das Dockerfile angepasst ‚Üí `npm run dev:rebuild` (Windows: `npm run win:dev:rebuild`).
- Komplettes Setup inkl. Datenbanken zur√ºcksetzen (z.‚ÄØB. nach kaputten Fixtures) ‚Üí `npm run dev:reset` (Windows: `npm run win:dev:reset`).
- Nur das RAG-Schema aktualisieren bzw. die Installation verifizieren ‚Üí `npm run jobs:rag` bzw. `npm run jobs:rag:health`.
- Demo-Tenant & Beispieldaten neu bef√ºllen ‚Üí `docker compose -f docker-compose.yml -f docker-compose.dev.yml exec web python manage.py create_demo_data` (Windows: gleicher Befehl in PowerShell).

Hinweis (Windows): PowerShell‚ÄëVarianten sind enthalten:
- `npm run win:dev:up`
- `npm run win:dev:check`
- `npm run win:dev:down`
- `npm run win:dev:rebuild` (optional mit `npm run win:dev:rebuild -- -WithFrontend`)
- `npm run win:dev:restart`
- `npm run win:dev:reset`
- `npm run win:rag:enable`
- `npm run win:jobs:rag`
- `npm run win:jobs:rag:health`

### Git Hooks (Lint vor Push)
- Installieren: 
  - macOS/Linux: `npm run hooks:install`
  - Windows: `npm run win:hooks:install`
- Wirkung: Vor jedem `git push` l√§uft automatisch `npm run lint` (ruff + black). Zum √úberspringen einmalig `SKIP_LINT=1 git push` setzen.

---
 
## Konfiguration (.env)
Ben√∂tigte Variablen (siehe `.env.example` oder `.env.dev.sample`):

- SECRET_KEY: geheimer Schl√ºssel f√ºr Django
- DEBUG: `true`/`false`
- DB_USER / DB_PASSWORD / DB_NAME: gemeinsame Dev‚ÄëCredentials; werden f√ºr den Container‚ÄëInit und DSNs genutzt.
- DATABASE_URL: Verbindungs-URL zur PostgreSQL-Datenbank (App‚ÄëDB, default: `postgresql://noesis2:noesis2@db:5432/noesis2`)
- REDIS_URL: Redis-Endpoint (z. B. f√ºr Celery)
- RAG_ENABLED: `true`/`false` zur Aktivierung des Retrieval-Augmented-Generation-Workflows.
  Aktiviere das Flag nur, wenn das `rag`-Schema inklusive `pgvector`-Extension (`CREATE EXTENSION IF NOT EXISTS vector;`)
  anhand von [`docs/rag/schema.sql`](docs/rag/schema.sql) bereitsteht und √ºber `DATABASE_URL` oder `RAG_DATABASE_URL`
  erreichbar ist. F√ºr den Datenbankzugriff wird `psycopg2` (oder das Bin√§r-Pendant `psycopg2-binary`) ben√∂tigt.
  Achtung: Mandanten-IDs m√ºssen UUIDs sein. √Ñltere nicht-UUID-Werte werden deterministisch gemappt, sollten aber per Migration
  bereinigt werden, bevor Deployments `RAG_ENABLED=true` setzen.

AI Core:
- LITELLM_BASE_URL: Basis-URL des LiteLLM-Proxys
- LITELLM_API_KEY: API-Key f√ºr den Proxy
- LITELLM_DATABASE_URL (optional): separates DB‚ÄëDSN f√ºr die LiteLLM Admin‚ÄëDB (default in Compose aus `DB_*` + `LITELLM_DB_NAME`)
- LANGFUSE_PUBLIC_KEY / LANGFUSE_SECRET_KEY: Schl√ºssel f√ºr Langfuse-Tracing
- LITELLM_SALT_KEY: Salt f√ºr Verschl√ºsselung gespeicherter Provider‚ÄëKeys in der Admin‚ÄëDB (empfohlen f√ºr Admin UI)

Die Settings lesen `.env` via `django-environ`. `DATABASE_URL` muss eine vollst√§ndige URL enthalten (inkl. URL-Encoding f√ºr Sonderzeichen); `REDIS_URL` wird sowohl f√ºr Celery als auch f√ºr Redis-basierte Integrationen verwendet.

Best Practice: In Dev einen gemeinsamen DB‚ÄëUser f√ºr App und LiteLLM verwenden (einfachere Einrichtung). In Produktion getrennte Rollen/DSNs je Dienst (Least Privilege).

## LiteLLM & Modelle (Prod vs. Lokal)
- Produktion (Cloud Run)
  - LiteLLM authentifiziert gegen Vertex AI per Service Account (ADC), kein API‚ÄëKey n√∂tig.
  - Regionensplit: Cloud Run `europe-west3`, Vertex `us-central1` (siehe `scripts/init_litellm_gcloud.sh` und CI).
  - Routing: `MODEL_ROUTING.yaml` zeigt auf `vertex_ai/*` Modelle (z. B. `vertex_ai/gemini-2.5-flash`).
  - CI setzt `VERTEXAI_PROJECT` und `VERTEXAI_LOCATION` und pinned die Cloud‚ÄëRun Service‚ÄëAccount‚ÄëIdentit√§t.

- Lokal (Docker Compose)
  - Vertex ADC steht lokal i. d. R. nicht zur Verf√ºgung. Nutze AI‚ÄëStudio (Gemini) √ºber LiteLLM‚ÄëConfig.
  - Datei `config/litellm-config.yaml` ist f√ºr AI‚ÄëStudio konfiguriert (`gemini/*` + `GEMINI_API_KEY`).
  - Erzeuge eine lokale Routing‚ÄëOverride, damit Django lokale Modelle anspricht:
    ```bash
    cp MODEL_ROUTING.local.yaml.sample MODEL_ROUTING.local.yaml
    ```
  - Setze in `.env` mindestens:
    - `GEMINI_API_KEY=<dein_ai_studio_key>`
    - `LITELLM_MASTER_KEY=<beliebiger_dev_key>`
  - Starte LiteLLM via Compose und teste:
    ```bash
    docker compose -f docker-compose.yml -f docker-compose.dev.yml up -d litellm
    bash scripts/smoke_litellm.sh
    ```

Hinweis: `MODEL_ROUTING.local.yaml` ist git‚Äëignored und √ºberschreibt nur lokal. In Prod wird ausschlie√ülich `MODEL_ROUTING.yaml` verwendet.

## GCloud Bootstrap (Windows)
Mit dem Skript `scripts/gcloud-bootstrap.ps1` kannst du dich per `gcloud` anmelden, ein Projekt/Region w√§hlen und h√§ufige Laufzeitwerte aus GCP sammeln (Redis, Cloud SQL, Cloud Run URLs). Die Werte werden sicher in `.env.gcloud` geschrieben (Git-ignored) und k√∂nnen selektiv in deine `.env` √ºbernommen werden.

PowerShell (Windows):

```powershell
pwsh -File scripts/gcloud-bootstrap.ps1
# oder nicht-interaktiv mit Vorgaben:
pwsh -File scripts/gcloud-bootstrap.ps1 -Region europe-west3 -Zone europe-west3-a

# Optional: Secrets explizit ziehen (schreibt sensible Werte in .env.gcloud!)
pwsh -File scripts/gcloud-bootstrap.ps1 -FetchSecrets -Secrets SECRET_KEY,LANGFUSE_KEY
```

Hinweise:
- Secrets werden standardm√§√üig nicht geladen. Mit `-FetchSecrets` + `-Secrets` kannst du gezielt Secret-Names laden, sofern dein Account berechtigt ist.
- F√ºr Cloud SQL im lokalen Setup bevorzugen wir weiterhin die lokale DB (Docker). Alternativ Cloud SQL Auth Proxy verwenden und `DB_HOST`/`DATABASE_URL` passend setzen.

## GCloud Bootstrap (Bash/WSL/Linux)
Das Bash-Pendant l√§uft unter WSL oder Linux. Es sammelt dieselben Werte und schreibt `.env.gcloud` (Git-ignored).

```bash
# Interaktiv
bash scripts/gcloud-bootstrap.sh

# Mit Parametern
bash scripts/gcloud-bootstrap.sh --region europe-west3 --zone europe-west3-a

# Optional Secrets (vorsichtig)
bash scripts/gcloud-bootstrap.sh --fetch-secrets \
  --secret SECRET_KEY --secret LANGFUSE_KEY
```

Voraussetzungen: `gcloud` im PATH. `jq` ist nicht erforderlich.

## Settings-Profile
Das alte `noesis2/settings.py` wurde entfernt; verwende ausschlie√ülich das modulare Paket `noesis2/settings/`.

- Standard: `noesis2.settings.development` (in `manage.py`, `asgi.py`, `wsgi.py` vorkonfiguriert)
- Production: `noesis2.settings.production`
- Umstellung per Env-Var: `DJANGO_SETTINGS_MODULE=noesis2.settings.production`

## Datenmigration und Standard-Organisation
Beim Upgrade auf die mandantenf√§hige Struktur muss jedem bestehenden Projekt
eine Organisation zugeordnet werden. Die Migration
`projects/migrations/0002_project_organization.py` legt f√ºr vorhandene Projekte
automatisch eine Organisation an. Sollten nach dem Deploy noch Projekte ohne
Organisation existieren (z.¬†B. nach einem manuellen Datenimport), kann der
Management-Befehl `assign_default_org` genutzt werden:

```bash
python manage.py assign_default_org
```

Der Befehl erzeugt f√ºr jedes betroffene Projekt eine neue Organisation und
aktualisiert das Projekt entsprechend.

## Tenant-Verwaltung

Eine ausf√ºhrliche Anleitung zur Einrichtung und Pflege von Mandanten (inkl. lokalem Setup, Admin/Operator‚ÄëRollen und X‚ÄëTenant‚ÄëSchema) befindet sich im Dokument [docs/multi-tenancy.md](docs/multi-tenancy.md).

## Operator-Kommandos (Makefile)

Im Projektwurzelverzeichnis stehen Makefile-Targets zur Verf√ºgung, um wiederkehrende Operator-Aufgaben auszuf√ºhren:

- `make jobs:migrate` ‚Äì f√ºhrt `python manage.py migrate_schemas --noinput` aus.
- `make jobs:bootstrap` ‚Äì legt den √∂ffentlichen Tenant per `bootstrap_public_tenant` an (`DOMAIN` erforderlich).
- `make tenant-new` ‚Äì erstellt ein neues Schema und die zugeh√∂rige Domain (`SCHEMA`, `NAME`, `DOMAIN`).
- `make tenant-superuser` ‚Äì erzeugt einen Superuser in einem Schema (`SCHEMA`, `USERNAME`, `PASSWORD`, optional `EMAIL`).
- `make jobs:rag` ‚Äì spielt [`docs/rag/schema.sql`](docs/rag/schema.sql) gegen den RAG-Store ein (`RAG_DATABASE_URL` oder fallback `DATABASE_URL`).
- `make jobs:rag:health` ‚Äì pr√ºft Schema, Tabellen und `vector`-Extension im RAG-Store (`RAG_DATABASE_URL` oder fallback `DATABASE_URL`).

Setze die ben√∂tigten Umgebungsvariablen vor dem Aufruf, z.‚ÄØB.:

```bash
export DOMAIN=demo.localhost
export SCHEMA=demo
export NAME="Demo GmbH"
export USERNAME=admin
export PASSWORD=changeme
export RAG_DATABASE_URL=postgresql://user:pass@host:5432/rag
```

`RAG_DATABASE_URL` kann leer bleiben, sofern `DATABASE_URL` auf dieselbe Instanz zeigt. F√ºr alternative Python-Binaries l√§sst sich `PYTHON` √ºberschreiben (`make PYTHON=python3 jobs:migrate`).

## LiteLLM Proxy (lokal)
- `.env.example` ‚Üí `.env` kopieren und `GOOGLE_API_KEY` setzen
- Start: `docker compose -f docker-compose.yml -f docker-compose.dev.yml up -d litellm`
- Healthcheck: `curl -s http://localhost:4000/health`
- Admin UI Login: Standardm√§√üig via Master Key (Wahl im UI). Alternativ User/Pass √ºber `UI_USERNAME`/`UI_PASSWORD` setzen (in dev/staging per Compose auf `DB_USER`/`DB_PASSWORD` voreingestellt).

## Frontend-Build (Tailwind v4 via PostCSS)
- Build/Watch: `npm run build:css` (wird in `npm run dev` automatisch gestartet)
- Konfiguration: `postcss.config.js` mit `@tailwindcss/postcss` und `autoprefixer`
- Eingabe/Ausgabe: `theme/static_src/input.css` ‚Üí `theme/static/css/output.css`

## Frontend-Richtlinien
- [Frontend-√úberblick](docs/frontend-ueberblick.md)
- Der vollst√§ndige Rahmen f√ºr React/TypeScript-Komponenten ist im [Frontend Master Prompt](docs/frontend-master-prompt.md) beschrieben.

## Testing
- Bevorzugt: in Docker ausf√ºhren, siehe Abschnitt "Lokales Testen".
- Schnelllauf: `docker compose -f docker-compose.dev.yml run --rm web sh -c "pip install -r requirements.txt -r requirements-dev.txt && python -m pytest -q"`
- Mit Coverage: `docker compose -f docker-compose.dev.yml run --rm web sh -c "pip install -r requirements.txt -r requirements-dev.txt && python -m pytest -q --cov=noesis2 --cov-report=term-missing"`
- Kurzbefehle: `npm run test:py` bzw. `npm run test:py:cov`
- Hinweis: Direktes `pytest` auf dem Host f√ºhrt h√§ufig zu DB-/Hostname-Fehlern (kein `db` im Compose-Netz). Nur nativ ausf√ºhren, wenn Postgres/Redis lokal verf√ºgbar und korrekt konfiguriert sind.

## Linting & Formatierung
- Pr√ºfen: `npm run lint` (ruff + black --check)
- Fixen: `npm run lint:fix` (ruff --fix + black)

## Abh√§ngigkeitsmanagement (pip-tools)
- Produktion: `pip-compile requirements.in` ‚Üí `requirements.txt`
- Entwicklung: `pip-compile requirements-dev.in` ‚Üí `requirements-dev.txt`
- Installation: `pip install -r requirements*.txt`

## Troubleshooting (Windows)
- Nur bei nativer Ausf√ºhrung ohne Docker relevant: Falls `pytest`, `black`, `ruff` oder `pip-compile` nicht gefunden werden, `%APPDATA%\Python\Python313\Scripts` zum PATH hinzuf√ºgen.
- `.env` sollte UTF‚Äë8 ohne BOM sein (bei Parsen-Fehlern Datei neu speichern).
